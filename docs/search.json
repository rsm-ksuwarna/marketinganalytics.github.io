[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Krithika Suwarna",
    "section": "",
    "text": "A Graduate student pursuing Masters in Business Analytics at the University of California, San Diego\nOver 3+ years of industry experience in successfully delivering high-impact technical solutions, managing complex projects, and driving innovation in Software Engineering and Data Analytics\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "This is Project 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nKrithika Suwarna\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/Project 3/hw1_questions.html",
    "href": "blog/Project 3/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "In their 2007 study published in the American Economic Review, economists Dean Karlan (Yale) and John A. List (University of Chicago) conducted a large-scale natural field experiment to better understand the behavioral economics of charitable giving. The core question they explored was:\n- Does the “price” of giving — as altered by matching grants — influence donor behavior?\n\n\nAt the time, fundraising professionals often used matching grants (e.g., “Your gift will be doubled!”) to incentivize donations. While widely used, these strategies were supported mostly by anecdotal success stories rather than empirical evidence. Karlan and List sought to provide rigorous experimental validation of whether — and how — matching grants influence giving behavior, and whether higher match ratios (e.g., 3:1 vs. 1:1) result in greater giving.\n\n\n\nThe researchers partnered with a politically active, liberal nonprofit organization. Their sample consisted of 50,083 previous donors to the organization.\nParticipants were randomly assigned to one of two broad categories:\n\nControl group (33% of sample; ~16,687 people):\n\nReceived a standard 4-page fundraising letter and reply card, with no mention of a matching grant.\n\nTreatment group (67% of sample; ~33,396 people):\n\nReceived the same letter, but with an added paragraph announcing a matching grant, and a modified reply card explaining the match.\n\n\nWithin the treatment group, there were further randomized sub-treatments based on:\n\nMatch Ratio: 1:1, 2:1, or 3:1\nMaximum Match Size: $25,000, $50,000, $100,000, or unspecified\nSuggested Donation Amounts: based on individual’s previous giving (equal to, 1.25×, or 1.5× their past gift)\n\n\n\n\nThe study delivered several key insights:\n\nMatching grants significantly increased giving:\n\nA matching grant (of any kind) increased revenue per solicitation by 19%\nIt also raised the probability of donation by 22%\n\nHigher match ratios did not increase giving further:\n\nThere was no statistically significant difference in giving behavior between 1:1, 2:1, and 3:1 matches.\nThis challenges the commonly held belief in fundraising that a higher match multiplier leads to greater motivation.\n\nPolitical geography influenced effectiveness:\n\nThe treatment was much more effective in “red” states (i.e., those that voted for George W. Bush in 2004) than in “blue” states.\nIn red states, the match increased donation revenue per letter by 55%.\nThis suggests that contextual and psychological factors, such as political identity and perceived urgency, play a significant role in donor responsiveness.\n\n\n\n\n\nThis experiment was among the first to rigorously analyze the “demand side” of charitable giving using a field experiment. It showed that: - Behavioral framing (e.g., matching) matters, but not necessarily the size of the incentive. - Donor characteristics — such as political leaning, donation history, and demographics — significantly influence how people respond to appeals. - Nonprofits might be overestimating the benefit of higher match ratios, potentially wasting strategic resources.\nIt also raised deeper questions about what motivates giving: Is it just economic rationality (maximizing impact per dollar)? Or do social cues, identity, and perceived urgency matter more?\n\n\n\n\nThe matching grants were real and funded by anonymous donors.\nDonors were not told who the matching donor was; it was described as a “concerned fellow member.”\nThe experiment used a real-world fundraising campaign — making it highly generalizable to actual nonprofit practices."
  },
  {
    "objectID": "blog/Project 3/hw1_questions.html#introduction",
    "href": "blog/Project 3/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "In their 2007 study published in the American Economic Review, economists Dean Karlan (Yale) and John A. List (University of Chicago) conducted a large-scale natural field experiment to better understand the behavioral economics of charitable giving. The core question they explored was:\n- Does the “price” of giving — as altered by matching grants — influence donor behavior?\n\n\nAt the time, fundraising professionals often used matching grants (e.g., “Your gift will be doubled!”) to incentivize donations. While widely used, these strategies were supported mostly by anecdotal success stories rather than empirical evidence. Karlan and List sought to provide rigorous experimental validation of whether — and how — matching grants influence giving behavior, and whether higher match ratios (e.g., 3:1 vs. 1:1) result in greater giving.\n\n\n\nThe researchers partnered with a politically active, liberal nonprofit organization. Their sample consisted of 50,083 previous donors to the organization.\nParticipants were randomly assigned to one of two broad categories:\n\nControl group (33% of sample; ~16,687 people):\n\nReceived a standard 4-page fundraising letter and reply card, with no mention of a matching grant.\n\nTreatment group (67% of sample; ~33,396 people):\n\nReceived the same letter, but with an added paragraph announcing a matching grant, and a modified reply card explaining the match.\n\n\nWithin the treatment group, there were further randomized sub-treatments based on:\n\nMatch Ratio: 1:1, 2:1, or 3:1\nMaximum Match Size: $25,000, $50,000, $100,000, or unspecified\nSuggested Donation Amounts: based on individual’s previous giving (equal to, 1.25×, or 1.5× their past gift)\n\n\n\n\nThe study delivered several key insights:\n\nMatching grants significantly increased giving:\n\nA matching grant (of any kind) increased revenue per solicitation by 19%\nIt also raised the probability of donation by 22%\n\nHigher match ratios did not increase giving further:\n\nThere was no statistically significant difference in giving behavior between 1:1, 2:1, and 3:1 matches.\nThis challenges the commonly held belief in fundraising that a higher match multiplier leads to greater motivation.\n\nPolitical geography influenced effectiveness:\n\nThe treatment was much more effective in “red” states (i.e., those that voted for George W. Bush in 2004) than in “blue” states.\nIn red states, the match increased donation revenue per letter by 55%.\nThis suggests that contextual and psychological factors, such as political identity and perceived urgency, play a significant role in donor responsiveness.\n\n\n\n\n\nThis experiment was among the first to rigorously analyze the “demand side” of charitable giving using a field experiment. It showed that: - Behavioral framing (e.g., matching) matters, but not necessarily the size of the incentive. - Donor characteristics — such as political leaning, donation history, and demographics — significantly influence how people respond to appeals. - Nonprofits might be overestimating the benefit of higher match ratios, potentially wasting strategic resources.\nIt also raised deeper questions about what motivates giving: Is it just economic rationality (maximizing impact per dollar)? Or do social cues, identity, and perceived urgency matter more?\n\n\n\n\nThe matching grants were real and funded by anonymous donors.\nDonors were not told who the matching donor was; it was described as a “concerned fellow member.”\nThe experiment used a real-world fundraising campaign — making it highly generalizable to actual nonprofit practices."
  },
  {
    "objectID": "blog/Project 3/hw1_questions.html#data",
    "href": "blog/Project 3/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.formula.api as smf\n\n# Load the Stata file\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Show the first few rows\nprint(\"First 5 rows:\")\nprint(df.head())\n\n# Summary statistics\nprint(\"\\nSummary statistics:\")\nprint(df.describe(include='all'))\n\n# Info about columns\nprint(\"\\nData info:\")\nprint(df.info())\n\nFirst 5 rows:\n   treatment  control    ratio  ratio2  ratio3      size  size25  size50  \\\n0          0        1  Control       0       0   Control       0       0   \n1          0        1  Control       0       0   Control       0       0   \n2          1        0        1       0       0  $100,000       0       0   \n3          1        0        1       0       0  Unstated       0       0   \n4          1        0        1       0       0   $50,000       0       1   \n\n   size100  sizeno  ... redcty  bluecty    pwhite    pblack  page18_39  \\\n0        0       0  ...    0.0      1.0  0.446493  0.527769   0.317591   \n1        0       0  ...    1.0      0.0       NaN       NaN        NaN   \n2        1       0  ...    0.0      1.0  0.935706  0.011948   0.276128   \n3        0       1  ...    1.0      0.0  0.888331  0.010760   0.279412   \n4        0       0  ...    0.0      1.0  0.759014  0.127421   0.442389   \n\n   ave_hh_sz  median_hhincome    powner  psch_atlstba  pop_propurban  \n0       2.10          28517.0  0.499807      0.324528            1.0  \n1        NaN              NaN       NaN           NaN            NaN  \n2       2.48          51175.0  0.721941      0.192668            1.0  \n3       2.65          79269.0  0.920431      0.412142            1.0  \n4       1.85          40908.0  0.416072      0.439965            1.0  \n\n[5 rows x 51 columns]\n\nSummary statistics:\n           treatment       control    ratio        ratio2        ratio3  \\\ncount   50083.000000  50083.000000    50083  50083.000000  50083.000000   \nunique           NaN           NaN        4           NaN           NaN   \ntop              NaN           NaN  Control           NaN           NaN   \nfreq             NaN           NaN    16687           NaN           NaN   \nmean        0.666813      0.333187      NaN      0.222311      0.222211   \nstd         0.471357      0.471357      NaN      0.415803      0.415736   \nmin         0.000000      0.000000      NaN      0.000000      0.000000   \n25%         0.000000      0.000000      NaN      0.000000      0.000000   \n50%         1.000000      0.000000      NaN      0.000000      0.000000   \n75%         1.000000      1.000000      NaN      0.000000      0.000000   \nmax         1.000000      1.000000      NaN      1.000000      1.000000   \n\n           size        size25        size50       size100        sizeno  ...  \\\ncount     50083  50083.000000  50083.000000  50083.000000  50083.000000  ...   \nunique        5           NaN           NaN           NaN           NaN  ...   \ntop     Control           NaN           NaN           NaN           NaN  ...   \nfreq      16687           NaN           NaN           NaN           NaN  ...   \nmean        NaN      0.166723      0.166623      0.166723      0.166743  ...   \nstd         NaN      0.372732      0.372643      0.372732      0.372750  ...   \nmin         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n25%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n50%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n75%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \nmax         NaN      1.000000      1.000000      1.000000      1.000000  ...   \n\n              redcty       bluecty        pwhite        pblack     page18_39  \\\ncount   49978.000000  49978.000000  48217.000000  48047.000000  48217.000000   \nunique           NaN           NaN           NaN           NaN           NaN   \ntop              NaN           NaN           NaN           NaN           NaN   \nfreq             NaN           NaN           NaN           NaN           NaN   \nmean        0.510245      0.488715      0.819599      0.086710      0.321694   \nstd         0.499900      0.499878      0.168561      0.135868      0.103039   \nmin         0.000000      0.000000      0.009418      0.000000      0.000000   \n25%         0.000000      0.000000      0.755845      0.014729      0.258311   \n50%         1.000000      0.000000      0.872797      0.036554      0.305534   \n75%         1.000000      1.000000      0.938827      0.090882      0.369132   \nmax         1.000000      1.000000      1.000000      0.989622      0.997544   \n\n           ave_hh_sz  median_hhincome        powner  psch_atlstba  \\\ncount   48221.000000     48209.000000  48214.000000  48215.000000   \nunique           NaN              NaN           NaN           NaN   \ntop              NaN              NaN           NaN           NaN   \nfreq             NaN              NaN           NaN           NaN   \nmean        2.429012     54815.700533      0.669418      0.391661   \nstd         0.378115     22027.316665      0.193405      0.186599   \nmin         0.000000      5000.000000      0.000000      0.000000   \n25%         2.210000     39181.000000      0.560222      0.235647   \n50%         2.440000     50673.000000      0.712296      0.373744   \n75%         2.660000     66005.000000      0.816798      0.530036   \nmax         5.270000    200001.000000      1.000000      1.000000   \n\n        pop_propurban  \ncount    48217.000000  \nunique            NaN  \ntop               NaN  \nfreq              NaN  \nmean         0.871968  \nstd          0.258654  \nmin          0.000000  \n25%          0.884929  \n50%          1.000000  \n75%          1.000000  \nmax          1.000000  \n\n[11 rows x 51 columns]\n\nData info:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\nNone\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nTo do this, I selected three pre-treatment variables that are plausibly unrelated to the treatment but relevant to donor behavior:\n\nmrm2: Number of months since last donation\nfreq: Number of prior donations\nhpa: Highest previous contribution\n\nThese variables were chosen to assess whether the randomization produced statistically similar groups on observable characteristics. For each variable, I performed:\n\nA manual t-test using the formula presented in the class slides:\nt = (X̄_T - X̄_C) / sqrt( (s_T^2 / n_T) + (s_C^2 / n_C) ) ​\nA simple linear regression of the form:\nVariable(𝑖) = 𝛼 + 𝛽⋅Treatment (𝑖) + 𝜖 (𝑖) V\n\nBoth approaches yielded consistent results — as expected, because the regression of a variable on a binary treatment indicator is mathematically equivalent to a two-sample t-test.\n\n\nResult Summary\n\n# Define the variables to test\nselected_vars = ['mrm2', 'freq', 'hpa', 'years', 'dormant']\nresults = []\n\nfor var in selected_vars:\n    temp_df = df[['treatment', var]].dropna()\n    \n    # Separate treatment and control groups\n    treat = temp_df[temp_df['treatment'] == 1][var]\n    control = temp_df[temp_df['treatment'] == 0][var]\n    \n    # Calculate means\n    mean_treat = treat.mean()\n    mean_control = control.mean()\n    mean_diff = mean_treat - mean_control\n\n    # Sample sizes and variances\n    n_treat = len(treat)\n    n_control = len(control)\n    var_treat = treat.var(ddof=1)\n    var_control = control.var(ddof=1)\n    \n    # Manual t-stat (class formula)\n    t_stat = mean_diff / np.sqrt(var_treat / n_treat + var_control / n_control)\n    \n    # Regression: outcome ~ treatment\n    model = smf.ols(f\"{var} ~ treatment\", data=temp_df).fit()\n    reg_coef = model.params['treatment']\n    reg_se = model.bse['treatment']\n    reg_t = model.tvalues['treatment']\n    reg_p = model.pvalues['treatment']\n    \n    # Append results\n    results.append([\n        var,\n        mean_treat,\n        mean_control,\n        mean_diff,\n        t_stat,\n        reg_coef,\n        reg_se,\n        reg_t,\n        reg_p\n    ])\n# Create a summary DataFrame\nsummary_df = pd.DataFrame(results, columns=[\n    'Variable',\n    'Mean (Treatment)',\n    'Mean (Control)',\n    'Mean Difference',\n    'T-test t-stat',\n    'Regression Coef',\n    'SE (Reg)',\n    't (Reg)',\n    'p-value (Reg)'\n])\n\n# Display the table\nprint(summary_df)\n\n  Variable  Mean (Treatment)  Mean (Control)  Mean Difference  T-test t-stat  \\\n0     mrm2         13.011828       12.998142         0.013686       0.119532   \n1     freq          8.035364        8.047342        -0.011979      -0.110845   \n2      hpa         59.597240       58.960167         0.637074       0.970427   \n3    years          6.078365        6.135914        -0.057549      -1.090918   \n4  dormant          0.523745        0.522922         0.000823       0.173880   \n\n   Regression Coef  SE (Reg)   t (Reg)  p-value (Reg)  \n0         0.013686  0.114534  0.119492       0.904886  \n1        -0.011979  0.108021 -0.110893       0.911702  \n2         0.637075  0.674762  0.944148       0.345099  \n3        -0.057549  0.052173 -1.103038       0.270016  \n4         0.000823  0.004735  0.173885       0.861957  \n\n\nThe purpose of this table is to demonstrate that the random assignment of participants was successful, with no systematic differences between groups prior to the intervention.\nIn my own balance test, I replicated this approach by performing both t-tests (using the manual formula from class slides) and simple linear regressions on the same variables. My results are fully consistent with the findings in Table 1: for mrm2, freq, and hpa, there were no statistically significant differences between the treatment and control groups at the 95% confidence level.\nJust like in the original paper, this serves as a crucial check of the experimental design. If randomization was successful — as both analyses confirm — then subsequent differences in giving behavior can be more confidently attributed to the treatment itself rather than underlying differences in donor characteristics. This validation strengthens the internal validity of the causal claims made later in the study."
  },
  {
    "objectID": "blog/Project 3/hw1_questions.html#experimental-results",
    "href": "blog/Project 3/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nimport matplotlib.pyplot as plt\n\n# Calculate the proportion of people who donated in each group\ntreatment_proportion = df[df['treatment'] == 1]['gave'].mean()\ncontrol_proportion = df[df['control'] == 1]['gave'].mean()\n\n# Create the barplot with different colors\nplt.bar(['Control', 'Treatment'], [control_proportion, treatment_proportion], color=['#FF9999', '#66B2FF'])\nplt.ylabel('Proportion of People Who Donated')\nplt.title('Proportion of Donors by Group')\nplt.show()\n\n\n\n\n\n\n\n\nThe bar plot compares the proportion of people who donated between the control and treatment groups. The control group (no match offer) has a donation rate of around 1.8%, while the treatment group (received a match offer) has a slightly higher donation rate of about 2.2%.\n\n# Define variables from Table 2A Panel A\nvariables_to_analyze = {\n    'gave': 'Response rate',\n    'amount': 'Dollars given, unconditional',\n}\n\n# Initialize result container\ntable2a_results = []\n\n# Perform t-test and regression for each variable\nfor var, description in variables_to_analyze.items():\n    df_var = df[['treatment', var]].dropna()\n    \n    treat = df_var[df_var['treatment'] == 1][var]\n    control = df_var[df_var['treatment'] == 0][var]\n    \n    mean_treat = treat.mean()\n    mean_control = control.mean()\n    mean_diff = mean_treat - mean_control\n    var_treat = treat.var(ddof=1)\n    var_control = control.var(ddof=1)\n    n_treat = len(treat)\n    n_control = len(control)\n    \n    t_stat = mean_diff / np.sqrt(var_treat / n_treat + var_control / n_control)\n    \n    reg_model = smf.ols(f'{var} ~ treatment', data=df_var).fit()\n    reg_coef = reg_model.params['treatment']\n    reg_se = reg_model.bse['treatment']\n    reg_t = reg_model.tvalues['treatment']\n    reg_p = reg_model.pvalues['treatment']\n    \n    table2a_results.append([\n        description,\n        mean_control,\n        mean_treat,\n        mean_diff,\n        t_stat,\n        reg_coef,\n        reg_se,\n        reg_t,\n        reg_p\n    ])\n\n# Create DataFrame\ntable2a_df = pd.DataFrame(table2a_results, columns=[\n    'Variable Description',\n    'Mean (Control)',\n    'Mean (Treatment)',\n    'Mean Difference',\n    'T-test t-stat',\n    'Regression Coef',\n    'SE (Reg)',\n    't (Reg)',\n    'p-value (Reg)'\n])\nprint(table2a_df)\n\n           Variable Description  Mean (Control)  Mean (Treatment)  \\\n0                 Response rate        0.017858          0.022039   \n1  Dollars given, unconditional        0.813268          0.966873   \n\n   Mean Difference  T-test t-stat  Regression Coef  SE (Reg)   t (Reg)  \\\n0         0.004180       3.209462         0.004180  0.001348  3.101361   \n1         0.153605       1.918262         0.153605  0.082561  1.860503   \n\n   p-value (Reg)  \n0       0.001927  \n1       0.062820  \n\n\nThe results show that individuals who were offered a matching donation were significantly more likely to give than those who were not. Although the difference—about 0.42 percentage points—may appear small, it is statistically meaningful, suggesting the increase is unlikely due to random chance.\nIn simpler terms:\nWhen people know their donation will be matched, they’re more motivated to give.\nEven a modest psychological nudge like a matching grant can have a real impact on behavior. This finding underscores the power of small, cost-effective interventions in fundraising — showing that people are more inclined to act when they feel their contribution is amplified.\n\nimport statsmodels.api as sm\n# Run Probit regression\n\ndf_probit = df[['gave', 'treatment']].dropna()\nprobit_model = sm.Probit(df_probit['gave'], sm.add_constant(df_probit['treatment'])).fit(disp=False)\n\n# Extract key results\nprobit_coef = probit_model.params['treatment']\nprobit_se = probit_model.bse['treatment']\nprobit_t = probit_model.tvalues['treatment']\nprobit_p = probit_model.pvalues['treatment']\n\n# Format results\nprobit_results = {\n    'Probit Coef': probit_coef,\n    'Standard Error': probit_se,\n    't-stat': probit_t,\n    'p-value': probit_p\n}\n\n# Print results\nprint(\"Probit Model Results for 'treatment':\")\nprint(f\"Coefficient: {probit_coef:.4f}\")\nprint(f\"Standard Error: {probit_se:.4f}\")\nprint(f\"t-statistic: {probit_t:.4f}\")\nprint(f\"p-value: {probit_p:.4f}\")\n\nProbit Model Results for 'treatment':\nCoefficient: 0.0868\nStandard Error: 0.0279\nt-statistic: 3.1129\np-value: 0.0019\n\n\nI ran a probit regression with the outcome variable being whether a donation was made, and the explanatory variable being assignment to treatment or control. My results closely match those reported in Table 3, Column 1 of Karlan & List (2007).\nThe coefficient on the treatment variable is positive and statistically significant, indicating that individuals who received a matching grant offer were significantly more likely to donate compared to those in the control group.\nAlthough the probit coefficient isn’t directly interpretable as a change in probability, its significance reinforces what I found in my earlier t-test and linear regression: even a small nudge — like offering to match donations — can meaningfully increase charitable behavior. This aligns with the broader takeaway that subtle incentives can shift decisions, especially in a fundraising context.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nfrom scipy import stats\n# Filter for treatment group and define match ratio groups\ndf_ratios = df[df['treatment'] == 1][['gave', 'ratio2', 'ratio3']].copy()\ndf_ratios['ratio1'] = ((df_ratios['ratio2'] == 0) & (df_ratios['ratio3'] == 0)).astype(int)\n\n# Extract 'gave' values by match ratio\ngroups = {\n    '1:1': df_ratios[df_ratios['ratio1'] == 1]['gave'],\n    '2:1': df_ratios[df_ratios['ratio2'] == 1]['gave'],\n    '3:1': df_ratios[df_ratios['ratio3'] == 1]['gave']\n}\n# Define pairwise comparisons\ncomparisons = [('2:1', '1:1'), ('3:1', '1:1'), ('3:1', '2:1')]\n\n# Run and print t-tests for each comparison\nfor group_a, group_b in comparisons:\n    t_stat, p_val = stats.ttest_ind(groups[group_a], groups[group_b], equal_var=False)\n    print(f\"{group_a} vs {group_b} match — t-statistic: {t_stat:.2f}, p-value: {p_val:.3f}\")\n\n2:1 vs 1:1 match — t-statistic: 0.97, p-value: 0.335\n3:1 vs 1:1 match — t-statistic: 1.02, p-value: 0.310\n3:1 vs 2:1 match — t-statistic: 0.05, p-value: 0.960\n\n\nThese results show that none of the pairwise differences between match ratios are statistically significant. Specifically, offering a 2:1 or 3:1 match did not increase the likelihood of donation compared to a 1:1 match. Even the comparison between 3:1 and 2:1 match rates produced a near-zero t-statistic and a p-value close to 1.0, indicating no meaningful difference.\nThis supports the authors’ observation in the paper that larger match ratios do not have an additional effect beyond simply offering a match. In plain terms, once donors know their gift will be matched, increasing the match size doesn’t seem to make them more likely to give.\n\n# Filter to treatment group and drop NA values\ndf_ratio_reg = df[df['treatment'] == 1][['gave', 'ratio2', 'ratio3']].dropna().copy()\n\n# Create ratio1 as 1 if neither ratio2 nor ratio3 is 1\ndf_ratio_reg['ratio1'] = ((df_ratio_reg['ratio2'] == 0) & (df_ratio_reg['ratio3'] == 0)).astype(int)\n\n# Run regression omitting ratio1 (1:1 match is the baseline)\nreg_model = smf.ols('gave ~ ratio2 + ratio3', data=df_ratio_reg).fit()\n\nprint(\" Regression Results: Effect of Match Ratio on Donation Likelihood\\n\")\n\n# Intercept represents the mean donation rate for the 1:1 match group\nprint(f\"1:1 match (Intercept) — Mean donation rate: {reg_model.params['Intercept']:.5f}, \"\n      f\"SE: {reg_model.bse['Intercept']:.5f}, \"\n      f\"p-value: {reg_model.pvalues['Intercept']:.4f}\")\n\n# 2:1 match coefficient vs 1:1\nprint(f\"2:1 match — Coefficient (vs 1:1): {reg_model.params['ratio2']:.5f}, \"\n      f\"SE: {reg_model.bse['ratio2']:.5f}, \"\n      f\"p-value: {reg_model.pvalues['ratio2']:.4f}\")\n\n# 3:1 match coefficient vs 1:1\nprint(f\"3:1 match — Coefficient (vs 1:1): {reg_model.params['ratio3']:.5f}, \"\n      f\"SE: {reg_model.bse['ratio3']:.5f}, \"\n      f\"p-value: {reg_model.pvalues['ratio3']:.4f}\")\n\n Regression Results: Effect of Match Ratio on Donation Likelihood\n\n1:1 match (Intercept) — Mean donation rate: 0.02075, SE: 0.00139, p-value: 0.0000\n2:1 match — Coefficient (vs 1:1): 0.00188, SE: 0.00197, p-value: 0.3383\n3:1 match — Coefficient (vs 1:1): 0.00198, SE: 0.00197, p-value: 0.3133\n\n\nThe regression examined whether different match ratios — 1:1 (baseline), 2:1, and 3:1 — affected the likelihood that individuals made a donation.\n\nThe intercept represents the average donation rate for the 1:1 match group, which is approximately 2.07%, and this estimate is highly statistically significant (p &lt; 0.0001). This confirms that, on average, about 2 out of every 100 individuals in the 1:1 group donated.\nThe coefficient for the 2:1 match group is 0.00188, which means donation rates in the 2:1 group were about 0.19 percentage points higher than the 1:1 group. However, the p-value is 0.338, indicating this difference is not statistically significant.\nThe coefficient for the 3:1 match group is 0.00198, suggesting a slightly higher donation rate than the 1:1 group by about 0.20 percentage points, but again, the p-value is 0.313, which is not statistically significant either.\n\n\n# Calculate raw response rate means directly from the data\nmean_1_1 = df_ratio_reg[df_ratio_reg['ratio1'] == 1]['gave'].mean()\nmean_2_1 = df_ratio_reg[df_ratio_reg['ratio2'] == 1]['gave'].mean()\nmean_3_1 = df_ratio_reg[df_ratio_reg['ratio3'] == 1]['gave'].mean()\n\n# Calculate differences in raw response rates\ndiff_2_vs_1_raw = mean_2_1 - mean_1_1\ndiff_3_vs_2_raw = mean_3_1 - mean_2_1\n\n# Calculate differences in fitted coefficients from regression (baseline is ratio1)\ncoef_2_1 = reg_model.params['ratio2']\ncoef_3_1 = reg_model.params['ratio3']\ndiff_3_vs_2_coef = coef_3_1 - coef_2_1\n\n# Combine results\nresponse_diff_results = {\n    'Raw Diff (2:1 - 1:1)': diff_2_vs_1_raw,\n    'Raw Diff (3:1 - 2:1)': diff_3_vs_2_raw,\n    'Coef Diff (3:1 - 2:1)': diff_3_vs_2_coef\n}\n\nprint(\"Response Rate Differences Between Match Ratios\\n\")\n\nprint(f\"Raw difference in donation rate (2:1 - 1:1): {diff_2_vs_1_raw:.5f} (0.19 percentage)\")\nprint(f\"Raw difference in donation rate (3:1 - 2:1): {diff_3_vs_2_raw:.5f} (0.01 percentage)\")\nprint(f\"Difference in regression coefficients (3:1 - 2:1): {diff_3_vs_2_coef:.5f} which matches the raw data difference exactly\")\n\nResponse Rate Differences Between Match Ratios\n\nRaw difference in donation rate (2:1 - 1:1): 0.00188 (0.19 percentage)\nRaw difference in donation rate (3:1 - 2:1): 0.00010 (0.01 percentage)\nDifference in regression coefficients (3:1 - 2:1): 0.00010 which matches the raw data difference exactly\n\n\nThe difference in donation rates between the 2:1 and 1:1 match groups is very small and not statistically significant. The difference between 3:1 and 2:1 is even smaller — practically zero.\nThese results provide consistent evidence that increasing the match ratio from 1:1 to 2:1 or 3:1 does not meaningfully improve donation rates. This supports the authors’ conclusion: while offering a match can increase giving, increasing the match size itself offers no additional behavioral advantage.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n# Calculate a t-test and run a regression of 'amount' on treatment status\nfrom scipy.stats import ttest_ind\ndf_amount = df[['amount', 'treatment']].dropna()\n\namount_treat = df_amount[df_amount['treatment'] == 1]['amount']\namount_control = df_amount[df_amount['treatment'] == 0]['amount']\n\nt_stat_amount, p_val_amount = ttest_ind(amount_treat, amount_control, equal_var=False)\n\n# Bivariate regression\nimport statsmodels.formula.api as smf\nreg_amount = smf.ols('amount ~ treatment', data=df_amount).fit()\n\n# Results with 4 digits after decimal\namount_analysis_results = {\n    'Mean (Treatment)': round(amount_treat.mean(), 4),\n    'Mean (Control)': round(amount_control.mean(), 4),\n    'Mean Difference': round(amount_treat.mean() - amount_control.mean(), 4),\n    'T-test t-stat': round(t_stat_amount, 4),\n    'T-test p-value': round(p_val_amount, 4),\n    'Regression Coef': round(reg_amount.params['treatment'], 4),\n    'Regression SE': round(reg_amount.bse['treatment'], 4),\n    'Regression p-value': round(reg_amount.pvalues['treatment'], 4)\n}\n\namount_analysis_results\n\n{'Mean (Treatment)': 0.9669,\n 'Mean (Control)': 0.8133,\n 'Mean Difference': 0.1536,\n 'T-test t-stat': 1.9183,\n 'T-test p-value': 0.0551,\n 'Regression Coef': 0.1536,\n 'Regression SE': 0.0826,\n 'Regression p-value': 0.0628}\n\n\nThe results suggest that individuals who received a matching donation offer gave slightly more than those in the control group — an increase of about $0.15 on average. However, this difference is not statistically significant at the conventional 5% level (though it’s very close, with p ≈ 0.06).\nThis implies a possible increase in donation amounts due to the treatment, but the evidence isn’t strong enough to be conclusive. It may indicate a marginal effect of the match offer on the size of the gift, but we can’t rule out the possibility that the observed difference happened by chance.\nLet me know if you want the results broken down further (e.g., conditional on giving only) or visualized\n\n# Filter to only those who made a positive donation\ndf_positive_donors = df[(df['amount'] &gt; 0) & df['treatment'].notna()]\n\n# Run t-test on positive donations\namount_treat_pos = df_positive_donors[df_positive_donors['treatment'] == 1]['amount']\namount_control_pos = df_positive_donors[df_positive_donors['treatment'] == 0]['amount']\nt_stat_pos, p_val_pos = ttest_ind(amount_treat_pos, amount_control_pos, equal_var=False)\n\n# Run regression on positive donations\nreg_pos = smf.ols('amount ~ treatment', data=df_positive_donors).fit()\n\n# Results\nconditional_donation_results = {\n    'Mean (Treatment)': amount_treat_pos.mean(),\n    'Mean (Control)': amount_control_pos.mean(),\n    'Mean Difference': amount_treat_pos.mean() - amount_control_pos.mean(),\n    'T-test t-stat': t_stat_pos,\n    'T-test p-value': p_val_pos,\n    'Regression Coef': reg_pos.params['treatment'],\n    'Regression SE': reg_pos.bse['treatment'],\n    'Regression p-value': reg_pos.pvalues['treatment']\n}\nconditional_donation_results\n\n{'Mean (Treatment)': 43.871876,\n 'Mean (Control)': 45.540268,\n 'Mean Difference': -1.6683922,\n 'T-test t-stat': -0.5846089794983359,\n 'T-test p-value': 0.5590471865673547,\n 'Regression Coef': -1.6683934553392605,\n 'Regression SE': 2.8723838572947864,\n 'Regression p-value': 0.5614755766155122}\n\n\nAmong donors, those in the treatment group actually gave slightly less than those in the control group — about $1.67 less on average. However, this difference is not statistically significant, and the confidence interval around this estimate would include zero.\nThis suggests that while the treatment increased the likelihood of donating, it did not increase the amount given among those who chose to donate. In other words, the match offer may help motivate people to give, but it doesn’t make them give more once they decide to donate.\nThe treatment Coefficient does not have a Causal Interpretation. By conditioning on donors only (i.e., those who gave &gt; 0), we lose the randomness of treatment assignment. This subset is no longer randomly assigned because treatment influenced whether someone gave. As a result, any differences in donation amounts conditional on giving may be confounded — the treatment coefficient in this regression does not have a clean causal interpretation.\n\nDistribution of Donation Amounts Among Donors by Treatment Status\n\n# Filter to only people who made a donation\ndf_donated = df[df['amount'] &gt; 0]\n\n# Separate treatment and control groups\ntreat_amounts = df_donated[df_donated['treatment'] == 1]['amount']\ncontrol_amounts = df_donated[df_donated['treatment'] == 0]['amount']\n\n# Calculate group means\nmean_treat = treat_amounts.mean()\nmean_control = control_amounts.mean()\n\n# Plot: Treatment Group\nplt.figure(figsize=(10, 5))\nplt.hist(treat_amounts, bins=50, color='skyblue', edgecolor='black')\nplt.axvline(mean_treat, color='red', linestyle='dashed', linewidth=2, label=f'Mean = ${mean_treat:.2f}')\nplt.title('Histogram of Donation Amounts - Treatment Group')\nplt.xlabel('Donation Amount ($)')\nplt.ylabel('Number of Donors')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Plot: Control Group\nplt.figure(figsize=(10, 5))\nplt.hist(control_amounts, bins=50, color='lightgreen', edgecolor='black')\nplt.axvline(mean_control, color='red', linestyle='dashed', linewidth=2, label=f'Mean = ${mean_control:.2f}')\nplt.title('Histogram of Donation Amounts - Control Group')\nplt.xlabel('Donation Amount ($)')\nplt.ylabel('Number of Donors')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere are the two histograms of donation amounts:\n\nThe first plot shows the distribution for the treatment group, with a red dashed line marking the average donation (around $43.87).\nThe second plot is for the control group, where the average donation is slightly higher (around $45.54)."
  },
  {
    "objectID": "blog/Project 3/hw1_questions.html#simulation-experiment",
    "href": "blog/Project 3/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nnp.random.seed(42)\n\n# Simulate draws from control (p = 0.018) and treatment (p = 0.022)\ncontrol_sim = np.random.binomial(1, 0.018, 100000)\ntreatment_sim = np.random.binomial(1, 0.022, 10000)\n\ncontrol_sample = np.random.choice(control_sim, size=10000, replace=False)\ndiff_vector = treatment_sim - control_sample\ncumulative_avg = np.cumsum(diff_vector) / np.arange(1, len(diff_vector) + 1)\n\n# Plot the cumulative average difference\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, color='blue', linewidth=1, label='Cumulative Average')\nplt.axhline(y=0.004, color='red', linestyle='--', label='True Difference = 0.004')\nplt.title('Simulation of LLN: Cumulative Average of Simulated Differences')\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average Difference')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis plot shows the cumulative average of 10,000 simulated differences in donation behavior between a treatment group (with donation probability 0.022) and a control group (with donation probability 0.018).\n\nThe blue line is the cumulative average of the difference: (treatment draw - control draw) over 10,000 samples.\nThe red dashed line marks the true difference in means, which is 0.004.\n\nAt first, the cumulative average fluctuates as randomness plays a strong role in small samples. But as more samples are added, the average steadily converges toward the true value of 0.004. This is a perfect illustration of the Law of Large Numbers: with enough observations, the sample mean approaches the population mean.\n\n\nCentral Limit Theorem\n\nnp.random.seed(42)\n\n# Simulation parameters\np_control = 0.018\np_treatment = 0.022\nreps = 1000\nsample_sizes = [50, 200, 500, 1000]\n\n# Container for plots\nfig, axes = plt.subplots(2, 2, figsize=(10, 8))\naxes = axes.flatten()\n\n# Perform simulation for each sample size\nfor idx, n in enumerate(sample_sizes):\n    diff_samples = []\n    for _ in range(reps):\n        control_sample = np.random.binomial(1, p_control, n)\n        treatment_sample = np.random.binomial(1, p_treatment, n)\n        diff = treatment_sample.mean() - control_sample.mean()\n        diff_samples.append(diff)\n\n    # Plot histogram\n    axes[idx].hist(diff_samples, bins=30, color='skyblue', edgecolor='black')\n    axes[idx].axvline(x=0, color='red', linestyle='--', label='Zero (Null)')\n    axes[idx].set_title(f\"Sample Size = {n}\")\n    axes[idx].set_xlabel(\"Difference in Means\")\n    axes[idx].set_ylabel(\"Frequency\")\n    axes[idx].legend()\n    axes[idx].grid(True)\n\n# Adjust layout and display\nplt.suptitle(\"Central Limit Theorem: Sampling Distribution of Difference in Means\", fontsize=14)\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])\nplt.show()\n\n\n\n\n\n\n\n\nThe four histograms above show the sampling distribution of the difference in means between treatment and control groups at increasing sample sizes: 50, 200, 500, and 1000. Each histogram is based on 1000 repetitions, where we took samples from Bernoulli distributions with:\n\np = 0.018 for the control group\np = 0.022 for the treatment group\n\nThe red dashed line at 0 represents the null hypothesis (i.e., no difference in means).\n\nInterpretation:\n\nAt n = 50: The distribution is quite spread out and lumpy. Zero falls near the center, but there’s a lot of variation.\nAt n = 200: The shape becomes more bell-like and narrower. The mean is closer to the expected difference.\nAt n = 500 and n = 1000: The distributions are smoother, tighter, and more symmetric. Importantly, zero is no longer centered, but appears more toward the edge of the distribution — showing that the observed differences are less likely under the null.\n\nAs the sample size increases, the sampling distribution becomes increasingly normal in shape due to the Central Limit Theorem. At the same time, the standard error shrinks, meaning the estimates become more precise. This allows us to more confidently detect small differences, such as the true difference in means of 0.004 between the treatment and control groups. Overall, this simulation demonstrates how the Central Limit Theorem enables us to make reliable statistical inferences with large samples, even when the underlying data are binary, such as in a Bernoulli distribution."
  },
  {
    "objectID": "blog/Project 1/index.html",
    "href": "blog/Project 1/index.html",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data\n\n\n\nI analyzed the data\n\nlibrary(tidyverse)\nmtcars |&gt; \n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point()"
  },
  {
    "objectID": "blog/Project 1/index.html#section-1-data",
    "href": "blog/Project 1/index.html#section-1-data",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data"
  },
  {
    "objectID": "blog/Project 1/index.html#section-2-analysis",
    "href": "blog/Project 1/index.html#section-2-analysis",
    "title": "This is Project 1",
    "section": "",
    "text": "I analyzed the data\n\nlibrary(tidyverse)\nmtcars |&gt; \n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point()"
  }
]