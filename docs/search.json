[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Krithika Suwarna",
    "section": "",
    "text": "A Graduate student pursuing Masters in Business Analytics at the University of California, San Diego\nOver 3+ years of industry experience in successfully delivering high-impact technical solutions, managing complex projects, and driving innovation in Software Engineering and Data Analytics\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "This is Project 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nKrithika Suwarna\n\n\nMay 25, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\n\n\nYour Name\n\n\nMay 25, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nMultinomial Logit Model\n\n\n\n\n\n\nYour Name\n\n\nMay 25, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/Project 3/hw1_questions.html",
    "href": "blog/Project 3/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "In their 2007 study published in the American Economic Review, economists Dean Karlan (Yale) and John A. List (University of Chicago) conducted a large-scale natural field experiment to better understand the behavioral economics of charitable giving. The core question they explored was:\n- Does the “price” of giving — as altered by matching grants — influence donor behavior?\n\n\nAt the time, fundraising professionals often used matching grants (e.g., “Your gift will be doubled!”) to incentivize donations. While widely used, these strategies were supported mostly by anecdotal success stories rather than empirical evidence. Karlan and List sought to provide rigorous experimental validation of whether — and how — matching grants influence giving behavior, and whether higher match ratios (e.g., 3:1 vs. 1:1) result in greater giving.\n\n\n\nThe researchers partnered with a politically active, liberal nonprofit organization. Their sample consisted of 50,083 previous donors to the organization.\nParticipants were randomly assigned to one of two broad categories:\n\nControl group (33% of sample; ~16,687 people):\n\nReceived a standard 4-page fundraising letter and reply card, with no mention of a matching grant.\n\nTreatment group (67% of sample; ~33,396 people):\n\nReceived the same letter, but with an added paragraph announcing a matching grant, and a modified reply card explaining the match.\n\n\nWithin the treatment group, there were further randomized sub-treatments based on:\n\nMatch Ratio: 1:1, 2:1, or 3:1\nMaximum Match Size: $25,000, $50,000, $100,000, or unspecified\nSuggested Donation Amounts: based on individual’s previous giving (equal to, 1.25×, or 1.5× their past gift)\n\n\n\n\nThe study delivered several key insights:\n\nMatching grants significantly increased giving:\n\nA matching grant (of any kind) increased revenue per solicitation by 19%\nIt also raised the probability of donation by 22%\n\nHigher match ratios did not increase giving further:\n\nThere was no statistically significant difference in giving behavior between 1:1, 2:1, and 3:1 matches.\nThis challenges the commonly held belief in fundraising that a higher match multiplier leads to greater motivation.\n\nPolitical geography influenced effectiveness:\n\nThe treatment was much more effective in “red” states (i.e., those that voted for George W. Bush in 2004) than in “blue” states.\nIn red states, the match increased donation revenue per letter by 55%.\nThis suggests that contextual and psychological factors, such as political identity and perceived urgency, play a significant role in donor responsiveness.\n\n\n\n\n\nThis experiment was among the first to rigorously analyze the “demand side” of charitable giving using a field experiment. It showed that: - Behavioral framing (e.g., matching) matters, but not necessarily the size of the incentive. - Donor characteristics — such as political leaning, donation history, and demographics — significantly influence how people respond to appeals. - Nonprofits might be overestimating the benefit of higher match ratios, potentially wasting strategic resources.\nIt also raised deeper questions about what motivates giving: Is it just economic rationality (maximizing impact per dollar)? Or do social cues, identity, and perceived urgency matter more?\n\n\n\n\nThe matching grants were real and funded by anonymous donors.\nDonors were not told who the matching donor was; it was described as a “concerned fellow member.”\nThe experiment used a real-world fundraising campaign — making it highly generalizable to actual nonprofit practices."
  },
  {
    "objectID": "blog/Project 3/hw1_questions.html#introduction",
    "href": "blog/Project 3/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "In their 2007 study published in the American Economic Review, economists Dean Karlan (Yale) and John A. List (University of Chicago) conducted a large-scale natural field experiment to better understand the behavioral economics of charitable giving. The core question they explored was:\n- Does the “price” of giving — as altered by matching grants — influence donor behavior?\n\n\nAt the time, fundraising professionals often used matching grants (e.g., “Your gift will be doubled!”) to incentivize donations. While widely used, these strategies were supported mostly by anecdotal success stories rather than empirical evidence. Karlan and List sought to provide rigorous experimental validation of whether — and how — matching grants influence giving behavior, and whether higher match ratios (e.g., 3:1 vs. 1:1) result in greater giving.\n\n\n\nThe researchers partnered with a politically active, liberal nonprofit organization. Their sample consisted of 50,083 previous donors to the organization.\nParticipants were randomly assigned to one of two broad categories:\n\nControl group (33% of sample; ~16,687 people):\n\nReceived a standard 4-page fundraising letter and reply card, with no mention of a matching grant.\n\nTreatment group (67% of sample; ~33,396 people):\n\nReceived the same letter, but with an added paragraph announcing a matching grant, and a modified reply card explaining the match.\n\n\nWithin the treatment group, there were further randomized sub-treatments based on:\n\nMatch Ratio: 1:1, 2:1, or 3:1\nMaximum Match Size: $25,000, $50,000, $100,000, or unspecified\nSuggested Donation Amounts: based on individual’s previous giving (equal to, 1.25×, or 1.5× their past gift)\n\n\n\n\nThe study delivered several key insights:\n\nMatching grants significantly increased giving:\n\nA matching grant (of any kind) increased revenue per solicitation by 19%\nIt also raised the probability of donation by 22%\n\nHigher match ratios did not increase giving further:\n\nThere was no statistically significant difference in giving behavior between 1:1, 2:1, and 3:1 matches.\nThis challenges the commonly held belief in fundraising that a higher match multiplier leads to greater motivation.\n\nPolitical geography influenced effectiveness:\n\nThe treatment was much more effective in “red” states (i.e., those that voted for George W. Bush in 2004) than in “blue” states.\nIn red states, the match increased donation revenue per letter by 55%.\nThis suggests that contextual and psychological factors, such as political identity and perceived urgency, play a significant role in donor responsiveness.\n\n\n\n\n\nThis experiment was among the first to rigorously analyze the “demand side” of charitable giving using a field experiment. It showed that: - Behavioral framing (e.g., matching) matters, but not necessarily the size of the incentive. - Donor characteristics — such as political leaning, donation history, and demographics — significantly influence how people respond to appeals. - Nonprofits might be overestimating the benefit of higher match ratios, potentially wasting strategic resources.\nIt also raised deeper questions about what motivates giving: Is it just economic rationality (maximizing impact per dollar)? Or do social cues, identity, and perceived urgency matter more?\n\n\n\n\nThe matching grants were real and funded by anonymous donors.\nDonors were not told who the matching donor was; it was described as a “concerned fellow member.”\nThe experiment used a real-world fundraising campaign — making it highly generalizable to actual nonprofit practices."
  },
  {
    "objectID": "blog/Project 3/hw1_questions.html#data",
    "href": "blog/Project 3/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.formula.api as smf\n\n# Load the Stata file\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Show the first few rows\nprint(\"First 5 rows:\")\nprint(df.head())\n\n# Summary statistics\nprint(\"\\nSummary statistics:\")\nprint(df.describe(include='all'))\n\n# Info about columns\nprint(\"\\nData info:\")\nprint(df.info())\n\nFirst 5 rows:\n   treatment  control    ratio  ratio2  ratio3      size  size25  size50  \\\n0          0        1  Control       0       0   Control       0       0   \n1          0        1  Control       0       0   Control       0       0   \n2          1        0        1       0       0  $100,000       0       0   \n3          1        0        1       0       0  Unstated       0       0   \n4          1        0        1       0       0   $50,000       0       1   \n\n   size100  sizeno  ... redcty  bluecty    pwhite    pblack  page18_39  \\\n0        0       0  ...    0.0      1.0  0.446493  0.527769   0.317591   \n1        0       0  ...    1.0      0.0       NaN       NaN        NaN   \n2        1       0  ...    0.0      1.0  0.935706  0.011948   0.276128   \n3        0       1  ...    1.0      0.0  0.888331  0.010760   0.279412   \n4        0       0  ...    0.0      1.0  0.759014  0.127421   0.442389   \n\n   ave_hh_sz  median_hhincome    powner  psch_atlstba  pop_propurban  \n0       2.10          28517.0  0.499807      0.324528            1.0  \n1        NaN              NaN       NaN           NaN            NaN  \n2       2.48          51175.0  0.721941      0.192668            1.0  \n3       2.65          79269.0  0.920431      0.412142            1.0  \n4       1.85          40908.0  0.416072      0.439965            1.0  \n\n[5 rows x 51 columns]\n\nSummary statistics:\n           treatment       control    ratio        ratio2        ratio3  \\\ncount   50083.000000  50083.000000    50083  50083.000000  50083.000000   \nunique           NaN           NaN        4           NaN           NaN   \ntop              NaN           NaN  Control           NaN           NaN   \nfreq             NaN           NaN    16687           NaN           NaN   \nmean        0.666813      0.333187      NaN      0.222311      0.222211   \nstd         0.471357      0.471357      NaN      0.415803      0.415736   \nmin         0.000000      0.000000      NaN      0.000000      0.000000   \n25%         0.000000      0.000000      NaN      0.000000      0.000000   \n50%         1.000000      0.000000      NaN      0.000000      0.000000   \n75%         1.000000      1.000000      NaN      0.000000      0.000000   \nmax         1.000000      1.000000      NaN      1.000000      1.000000   \n\n           size        size25        size50       size100        sizeno  ...  \\\ncount     50083  50083.000000  50083.000000  50083.000000  50083.000000  ...   \nunique        5           NaN           NaN           NaN           NaN  ...   \ntop     Control           NaN           NaN           NaN           NaN  ...   \nfreq      16687           NaN           NaN           NaN           NaN  ...   \nmean        NaN      0.166723      0.166623      0.166723      0.166743  ...   \nstd         NaN      0.372732      0.372643      0.372732      0.372750  ...   \nmin         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n25%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n50%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n75%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \nmax         NaN      1.000000      1.000000      1.000000      1.000000  ...   \n\n              redcty       bluecty        pwhite        pblack     page18_39  \\\ncount   49978.000000  49978.000000  48217.000000  48047.000000  48217.000000   \nunique           NaN           NaN           NaN           NaN           NaN   \ntop              NaN           NaN           NaN           NaN           NaN   \nfreq             NaN           NaN           NaN           NaN           NaN   \nmean        0.510245      0.488715      0.819599      0.086710      0.321694   \nstd         0.499900      0.499878      0.168561      0.135868      0.103039   \nmin         0.000000      0.000000      0.009418      0.000000      0.000000   \n25%         0.000000      0.000000      0.755845      0.014729      0.258311   \n50%         1.000000      0.000000      0.872797      0.036554      0.305534   \n75%         1.000000      1.000000      0.938827      0.090882      0.369132   \nmax         1.000000      1.000000      1.000000      0.989622      0.997544   \n\n           ave_hh_sz  median_hhincome        powner  psch_atlstba  \\\ncount   48221.000000     48209.000000  48214.000000  48215.000000   \nunique           NaN              NaN           NaN           NaN   \ntop              NaN              NaN           NaN           NaN   \nfreq             NaN              NaN           NaN           NaN   \nmean        2.429012     54815.700533      0.669418      0.391661   \nstd         0.378115     22027.316665      0.193405      0.186599   \nmin         0.000000      5000.000000      0.000000      0.000000   \n25%         2.210000     39181.000000      0.560222      0.235647   \n50%         2.440000     50673.000000      0.712296      0.373744   \n75%         2.660000     66005.000000      0.816798      0.530036   \nmax         5.270000    200001.000000      1.000000      1.000000   \n\n        pop_propurban  \ncount    48217.000000  \nunique            NaN  \ntop               NaN  \nfreq              NaN  \nmean         0.871968  \nstd          0.258654  \nmin          0.000000  \n25%          0.884929  \n50%          1.000000  \n75%          1.000000  \nmax          1.000000  \n\n[11 rows x 51 columns]\n\nData info:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\nNone\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nTo do this, I selected three pre-treatment variables that are plausibly unrelated to the treatment but relevant to donor behavior:\n\nmrm2: Number of months since last donation\nfreq: Number of prior donations\nhpa: Highest previous contribution\n\nThese variables were chosen to assess whether the randomization produced statistically similar groups on observable characteristics. For each variable, I performed:\n\nA manual t-test using the formula presented in the class slides:\nt = (X̄_T - X̄_C) / sqrt( (s_T^2 / n_T) + (s_C^2 / n_C) ) ​\nA simple linear regression of the form:\nVariable(𝑖) = 𝛼 + 𝛽⋅Treatment (𝑖) + 𝜖 (𝑖) V\n\nBoth approaches yielded consistent results — as expected, because the regression of a variable on a binary treatment indicator is mathematically equivalent to a two-sample t-test.\n\n\nResult Summary\n\n# Define the variables to test\nselected_vars = ['mrm2', 'freq', 'hpa', 'years', 'dormant']\nresults = []\n\nfor var in selected_vars:\n    temp_df = df[['treatment', var]].dropna()\n    \n    # Separate treatment and control groups\n    treat = temp_df[temp_df['treatment'] == 1][var]\n    control = temp_df[temp_df['treatment'] == 0][var]\n    \n    # Calculate means\n    mean_treat = treat.mean()\n    mean_control = control.mean()\n    mean_diff = mean_treat - mean_control\n\n    # Sample sizes and variances\n    n_treat = len(treat)\n    n_control = len(control)\n    var_treat = treat.var(ddof=1)\n    var_control = control.var(ddof=1)\n    \n    # Manual t-stat (class formula)\n    t_stat = mean_diff / np.sqrt(var_treat / n_treat + var_control / n_control)\n    \n    # Regression: outcome ~ treatment\n    model = smf.ols(f\"{var} ~ treatment\", data=temp_df).fit()\n    reg_coef = model.params['treatment']\n    reg_se = model.bse['treatment']\n    reg_t = model.tvalues['treatment']\n    reg_p = model.pvalues['treatment']\n    \n    # Append results\n    results.append([\n        var,\n        mean_treat,\n        mean_control,\n        mean_diff,\n        t_stat,\n        reg_coef,\n        reg_se,\n        reg_t,\n        reg_p\n    ])\n# Create a summary DataFrame\nsummary_df = pd.DataFrame(results, columns=[\n    'Variable',\n    'Mean (Treatment)',\n    'Mean (Control)',\n    'Mean Difference',\n    'T-test t-stat',\n    'Regression Coef',\n    'SE (Reg)',\n    't (Reg)',\n    'p-value (Reg)'\n])\n\n# Display the table\nprint(summary_df)\n\n  Variable  Mean (Treatment)  Mean (Control)  Mean Difference  T-test t-stat  \\\n0     mrm2         13.011828       12.998142         0.013686       0.119532   \n1     freq          8.035364        8.047342        -0.011979      -0.110845   \n2      hpa         59.597240       58.960167         0.637074       0.970427   \n3    years          6.078365        6.135914        -0.057549      -1.090918   \n4  dormant          0.523745        0.522922         0.000823       0.173880   \n\n   Regression Coef  SE (Reg)   t (Reg)  p-value (Reg)  \n0         0.013686  0.114534  0.119492       0.904886  \n1        -0.011979  0.108021 -0.110893       0.911702  \n2         0.637075  0.674762  0.944148       0.345099  \n3        -0.057549  0.052173 -1.103038       0.270016  \n4         0.000823  0.004735  0.173885       0.861957  \n\n\nThe purpose of this table is to demonstrate that the random assignment of participants was successful, with no systematic differences between groups prior to the intervention.\nIn my own balance test, I replicated this approach by performing both t-tests (using the manual formula from class slides) and simple linear regressions on the same variables. My results are fully consistent with the findings in Table 1: for mrm2, freq, and hpa, there were no statistically significant differences between the treatment and control groups at the 95% confidence level.\nJust like in the original paper, this serves as a crucial check of the experimental design. If randomization was successful — as both analyses confirm — then subsequent differences in giving behavior can be more confidently attributed to the treatment itself rather than underlying differences in donor characteristics. This validation strengthens the internal validity of the causal claims made later in the study."
  },
  {
    "objectID": "blog/Project 3/hw1_questions.html#experimental-results",
    "href": "blog/Project 3/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nimport matplotlib.pyplot as plt\n\n# Calculate the proportion of people who donated in each group\ntreatment_proportion = df[df['treatment'] == 1]['gave'].mean()\ncontrol_proportion = df[df['control'] == 1]['gave'].mean()\n\n# Create the barplot with different colors\nplt.bar(['Control', 'Treatment'], [control_proportion, treatment_proportion], color=['#FF9999', '#66B2FF'])\nplt.ylabel('Proportion of People Who Donated')\nplt.title('Proportion of Donors by Group')\nplt.show()\n\n\n\n\n\n\n\n\nThe bar plot compares the proportion of people who donated between the control and treatment groups. The control group (no match offer) has a donation rate of around 1.8%, while the treatment group (received a match offer) has a slightly higher donation rate of about 2.2%.\n\n# Define variables from Table 2A Panel A\nvariables_to_analyze = {\n    'gave': 'Response rate',\n    'amount': 'Dollars given, unconditional',\n}\n\n# Initialize result container\ntable2a_results = []\n\n# Perform t-test and regression for each variable\nfor var, description in variables_to_analyze.items():\n    df_var = df[['treatment', var]].dropna()\n    \n    treat = df_var[df_var['treatment'] == 1][var]\n    control = df_var[df_var['treatment'] == 0][var]\n    \n    mean_treat = treat.mean()\n    mean_control = control.mean()\n    mean_diff = mean_treat - mean_control\n    var_treat = treat.var(ddof=1)\n    var_control = control.var(ddof=1)\n    n_treat = len(treat)\n    n_control = len(control)\n    \n    t_stat = mean_diff / np.sqrt(var_treat / n_treat + var_control / n_control)\n    \n    reg_model = smf.ols(f'{var} ~ treatment', data=df_var).fit()\n    reg_coef = reg_model.params['treatment']\n    reg_se = reg_model.bse['treatment']\n    reg_t = reg_model.tvalues['treatment']\n    reg_p = reg_model.pvalues['treatment']\n    \n    table2a_results.append([\n        description,\n        mean_control,\n        mean_treat,\n        mean_diff,\n        t_stat,\n        reg_coef,\n        reg_se,\n        reg_t,\n        reg_p\n    ])\n\n# Create DataFrame\ntable2a_df = pd.DataFrame(table2a_results, columns=[\n    'Variable Description',\n    'Mean (Control)',\n    'Mean (Treatment)',\n    'Mean Difference',\n    'T-test t-stat',\n    'Regression Coef',\n    'SE (Reg)',\n    't (Reg)',\n    'p-value (Reg)'\n])\nprint(table2a_df)\n\n           Variable Description  Mean (Control)  Mean (Treatment)  \\\n0                 Response rate        0.017858          0.022039   \n1  Dollars given, unconditional        0.813268          0.966873   \n\n   Mean Difference  T-test t-stat  Regression Coef  SE (Reg)   t (Reg)  \\\n0         0.004180       3.209462         0.004180  0.001348  3.101361   \n1         0.153605       1.918262         0.153605  0.082561  1.860503   \n\n   p-value (Reg)  \n0       0.001927  \n1       0.062820  \n\n\nThe results show that individuals who were offered a matching donation were significantly more likely to give than those who were not. Although the difference—about 0.42 percentage points—may appear small, it is statistically meaningful, suggesting the increase is unlikely due to random chance.\nIn simpler terms:\nWhen people know their donation will be matched, they’re more motivated to give.\nEven a modest psychological nudge like a matching grant can have a real impact on behavior. This finding underscores the power of small, cost-effective interventions in fundraising — showing that people are more inclined to act when they feel their contribution is amplified.\n\nimport statsmodels.api as sm\n# Run Probit regression\n\ndf_probit = df[['gave', 'treatment']].dropna()\nprobit_model = sm.Probit(df_probit['gave'], sm.add_constant(df_probit['treatment'])).fit(disp=False)\n\n# Extract key results\nprobit_coef = probit_model.params['treatment']\nprobit_se = probit_model.bse['treatment']\nprobit_t = probit_model.tvalues['treatment']\nprobit_p = probit_model.pvalues['treatment']\n\n# Format results\nprobit_results = {\n    'Probit Coef': probit_coef,\n    'Standard Error': probit_se,\n    't-stat': probit_t,\n    'p-value': probit_p\n}\n\n# Print results\nprint(\"Probit Model Results for 'treatment':\")\nprint(f\"Coefficient: {probit_coef:.4f}\")\nprint(f\"Standard Error: {probit_se:.4f}\")\nprint(f\"t-statistic: {probit_t:.4f}\")\nprint(f\"p-value: {probit_p:.4f}\")\n\nProbit Model Results for 'treatment':\nCoefficient: 0.0868\nStandard Error: 0.0279\nt-statistic: 3.1129\np-value: 0.0019\n\n\nI ran a probit regression with the outcome variable being whether a donation was made, and the explanatory variable being assignment to treatment or control. My results closely match those reported in Table 3, Column 1 of Karlan & List (2007).\nThe coefficient on the treatment variable is positive and statistically significant, indicating that individuals who received a matching grant offer were significantly more likely to donate compared to those in the control group.\nAlthough the probit coefficient isn’t directly interpretable as a change in probability, its significance reinforces what I found in my earlier t-test and linear regression: even a small nudge — like offering to match donations — can meaningfully increase charitable behavior. This aligns with the broader takeaway that subtle incentives can shift decisions, especially in a fundraising context.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nfrom scipy import stats\n# Filter for treatment group and define match ratio groups\ndf_ratios = df[df['treatment'] == 1][['gave', 'ratio2', 'ratio3']].copy()\ndf_ratios['ratio1'] = ((df_ratios['ratio2'] == 0) & (df_ratios['ratio3'] == 0)).astype(int)\n\n# Extract 'gave' values by match ratio\ngroups = {\n    '1:1': df_ratios[df_ratios['ratio1'] == 1]['gave'],\n    '2:1': df_ratios[df_ratios['ratio2'] == 1]['gave'],\n    '3:1': df_ratios[df_ratios['ratio3'] == 1]['gave']\n}\n# Define pairwise comparisons\ncomparisons = [('2:1', '1:1'), ('3:1', '1:1'), ('3:1', '2:1')]\n\n# Run and print t-tests for each comparison\nfor group_a, group_b in comparisons:\n    t_stat, p_val = stats.ttest_ind(groups[group_a], groups[group_b], equal_var=False)\n    print(f\"{group_a} vs {group_b} match — t-statistic: {t_stat:.2f}, p-value: {p_val:.3f}\")\n\n2:1 vs 1:1 match — t-statistic: 0.97, p-value: 0.335\n3:1 vs 1:1 match — t-statistic: 1.02, p-value: 0.310\n3:1 vs 2:1 match — t-statistic: 0.05, p-value: 0.960\n\n\nThese results show that none of the pairwise differences between match ratios are statistically significant. Specifically, offering a 2:1 or 3:1 match did not increase the likelihood of donation compared to a 1:1 match. Even the comparison between 3:1 and 2:1 match rates produced a near-zero t-statistic and a p-value close to 1.0, indicating no meaningful difference.\nThis supports the authors’ observation in the paper that larger match ratios do not have an additional effect beyond simply offering a match. In plain terms, once donors know their gift will be matched, increasing the match size doesn’t seem to make them more likely to give.\n\n# Filter to treatment group and drop NA values\ndf_ratio_reg = df[df['treatment'] == 1][['gave', 'ratio2', 'ratio3']].dropna().copy()\n\n# Create ratio1 as 1 if neither ratio2 nor ratio3 is 1\ndf_ratio_reg['ratio1'] = ((df_ratio_reg['ratio2'] == 0) & (df_ratio_reg['ratio3'] == 0)).astype(int)\n\n# Run regression omitting ratio1 (1:1 match is the baseline)\nreg_model = smf.ols('gave ~ ratio2 + ratio3', data=df_ratio_reg).fit()\n\nprint(\" Regression Results: Effect of Match Ratio on Donation Likelihood\\n\")\n\n# Intercept represents the mean donation rate for the 1:1 match group\nprint(f\"1:1 match (Intercept) — Mean donation rate: {reg_model.params['Intercept']:.5f}, \"\n      f\"SE: {reg_model.bse['Intercept']:.5f}, \"\n      f\"p-value: {reg_model.pvalues['Intercept']:.4f}\")\n\n# 2:1 match coefficient vs 1:1\nprint(f\"2:1 match — Coefficient (vs 1:1): {reg_model.params['ratio2']:.5f}, \"\n      f\"SE: {reg_model.bse['ratio2']:.5f}, \"\n      f\"p-value: {reg_model.pvalues['ratio2']:.4f}\")\n\n# 3:1 match coefficient vs 1:1\nprint(f\"3:1 match — Coefficient (vs 1:1): {reg_model.params['ratio3']:.5f}, \"\n      f\"SE: {reg_model.bse['ratio3']:.5f}, \"\n      f\"p-value: {reg_model.pvalues['ratio3']:.4f}\")\n\n Regression Results: Effect of Match Ratio on Donation Likelihood\n\n1:1 match (Intercept) — Mean donation rate: 0.02075, SE: 0.00139, p-value: 0.0000\n2:1 match — Coefficient (vs 1:1): 0.00188, SE: 0.00197, p-value: 0.3383\n3:1 match — Coefficient (vs 1:1): 0.00198, SE: 0.00197, p-value: 0.3133\n\n\nThe regression examined whether different match ratios — 1:1 (baseline), 2:1, and 3:1 — affected the likelihood that individuals made a donation.\n\nThe intercept represents the average donation rate for the 1:1 match group, which is approximately 2.07%, and this estimate is highly statistically significant (p &lt; 0.0001). This confirms that, on average, about 2 out of every 100 individuals in the 1:1 group donated.\nThe coefficient for the 2:1 match group is 0.00188, which means donation rates in the 2:1 group were about 0.19 percentage points higher than the 1:1 group. However, the p-value is 0.338, indicating this difference is not statistically significant.\nThe coefficient for the 3:1 match group is 0.00198, suggesting a slightly higher donation rate than the 1:1 group by about 0.20 percentage points, but again, the p-value is 0.313, which is not statistically significant either.\n\n\n# Calculate raw response rate means directly from the data\nmean_1_1 = df_ratio_reg[df_ratio_reg['ratio1'] == 1]['gave'].mean()\nmean_2_1 = df_ratio_reg[df_ratio_reg['ratio2'] == 1]['gave'].mean()\nmean_3_1 = df_ratio_reg[df_ratio_reg['ratio3'] == 1]['gave'].mean()\n\n# Calculate differences in raw response rates\ndiff_2_vs_1_raw = mean_2_1 - mean_1_1\ndiff_3_vs_2_raw = mean_3_1 - mean_2_1\n\n# Calculate differences in fitted coefficients from regression (baseline is ratio1)\ncoef_2_1 = reg_model.params['ratio2']\ncoef_3_1 = reg_model.params['ratio3']\ndiff_3_vs_2_coef = coef_3_1 - coef_2_1\n\n# Combine results\nresponse_diff_results = {\n    'Raw Diff (2:1 - 1:1)': diff_2_vs_1_raw,\n    'Raw Diff (3:1 - 2:1)': diff_3_vs_2_raw,\n    'Coef Diff (3:1 - 2:1)': diff_3_vs_2_coef\n}\n\nprint(\"Response Rate Differences Between Match Ratios\\n\")\n\nprint(f\"Raw difference in donation rate (2:1 - 1:1): {diff_2_vs_1_raw:.5f} (0.19 percentage)\")\nprint(f\"Raw difference in donation rate (3:1 - 2:1): {diff_3_vs_2_raw:.5f} (0.01 percentage)\")\nprint(f\"Difference in regression coefficients (3:1 - 2:1): {diff_3_vs_2_coef:.5f} which matches the raw data difference exactly\")\n\nResponse Rate Differences Between Match Ratios\n\nRaw difference in donation rate (2:1 - 1:1): 0.00188 (0.19 percentage)\nRaw difference in donation rate (3:1 - 2:1): 0.00010 (0.01 percentage)\nDifference in regression coefficients (3:1 - 2:1): 0.00010 which matches the raw data difference exactly\n\n\nThe difference in donation rates between the 2:1 and 1:1 match groups is very small and not statistically significant. The difference between 3:1 and 2:1 is even smaller — practically zero.\nThese results provide consistent evidence that increasing the match ratio from 1:1 to 2:1 or 3:1 does not meaningfully improve donation rates. This supports the authors’ conclusion: while offering a match can increase giving, increasing the match size itself offers no additional behavioral advantage.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n# Calculate a t-test and run a regression of 'amount' on treatment status\nfrom scipy.stats import ttest_ind\ndf_amount = df[['amount', 'treatment']].dropna()\n\namount_treat = df_amount[df_amount['treatment'] == 1]['amount']\namount_control = df_amount[df_amount['treatment'] == 0]['amount']\n\nt_stat_amount, p_val_amount = ttest_ind(amount_treat, amount_control, equal_var=False)\n\n# Bivariate regression\nimport statsmodels.formula.api as smf\nreg_amount = smf.ols('amount ~ treatment', data=df_amount).fit()\n\n# Results with 4 digits after decimal\namount_analysis_results = {\n    'Mean (Treatment)': round(amount_treat.mean(), 4),\n    'Mean (Control)': round(amount_control.mean(), 4),\n    'Mean Difference': round(amount_treat.mean() - amount_control.mean(), 4),\n    'T-test t-stat': round(t_stat_amount, 4),\n    'T-test p-value': round(p_val_amount, 4),\n    'Regression Coef': round(reg_amount.params['treatment'], 4),\n    'Regression SE': round(reg_amount.bse['treatment'], 4),\n    'Regression p-value': round(reg_amount.pvalues['treatment'], 4)\n}\n\namount_analysis_results\n\n{'Mean (Treatment)': 0.9669,\n 'Mean (Control)': 0.8133,\n 'Mean Difference': 0.1536,\n 'T-test t-stat': 1.9183,\n 'T-test p-value': 0.0551,\n 'Regression Coef': 0.1536,\n 'Regression SE': 0.0826,\n 'Regression p-value': 0.0628}\n\n\nThe results suggest that individuals who received a matching donation offer gave slightly more than those in the control group — an increase of about $0.15 on average. However, this difference is not statistically significant at the conventional 5% level (though it’s very close, with p ≈ 0.06).\nThis implies a possible increase in donation amounts due to the treatment, but the evidence isn’t strong enough to be conclusive. It may indicate a marginal effect of the match offer on the size of the gift, but we can’t rule out the possibility that the observed difference happened by chance.\nLet me know if you want the results broken down further (e.g., conditional on giving only) or visualized\n\n# Filter to only those who made a positive donation\ndf_positive_donors = df[(df['amount'] &gt; 0) & df['treatment'].notna()]\n\n# Run t-test on positive donations\namount_treat_pos = df_positive_donors[df_positive_donors['treatment'] == 1]['amount']\namount_control_pos = df_positive_donors[df_positive_donors['treatment'] == 0]['amount']\nt_stat_pos, p_val_pos = ttest_ind(amount_treat_pos, amount_control_pos, equal_var=False)\n\n# Run regression on positive donations\nreg_pos = smf.ols('amount ~ treatment', data=df_positive_donors).fit()\n\n# Results\nconditional_donation_results = {\n    'Mean (Treatment)': amount_treat_pos.mean(),\n    'Mean (Control)': amount_control_pos.mean(),\n    'Mean Difference': amount_treat_pos.mean() - amount_control_pos.mean(),\n    'T-test t-stat': t_stat_pos,\n    'T-test p-value': p_val_pos,\n    'Regression Coef': reg_pos.params['treatment'],\n    'Regression SE': reg_pos.bse['treatment'],\n    'Regression p-value': reg_pos.pvalues['treatment']\n}\nconditional_donation_results\n\n{'Mean (Treatment)': 43.871876,\n 'Mean (Control)': 45.540268,\n 'Mean Difference': -1.6683922,\n 'T-test t-stat': -0.5846089794983359,\n 'T-test p-value': 0.5590471865673547,\n 'Regression Coef': -1.6683934553392605,\n 'Regression SE': 2.8723838572947864,\n 'Regression p-value': 0.5614755766155122}\n\n\nAmong donors, those in the treatment group actually gave slightly less than those in the control group — about $1.67 less on average. However, this difference is not statistically significant, and the confidence interval around this estimate would include zero.\nThis suggests that while the treatment increased the likelihood of donating, it did not increase the amount given among those who chose to donate. In other words, the match offer may help motivate people to give, but it doesn’t make them give more once they decide to donate.\nThe treatment Coefficient does not have a Causal Interpretation. By conditioning on donors only (i.e., those who gave &gt; 0), we lose the randomness of treatment assignment. This subset is no longer randomly assigned because treatment influenced whether someone gave. As a result, any differences in donation amounts conditional on giving may be confounded — the treatment coefficient in this regression does not have a clean causal interpretation.\n\nDistribution of Donation Amounts Among Donors by Treatment Status\n\n# Filter to only people who made a donation\ndf_donated = df[df['amount'] &gt; 0]\n\n# Separate treatment and control groups\ntreat_amounts = df_donated[df_donated['treatment'] == 1]['amount']\ncontrol_amounts = df_donated[df_donated['treatment'] == 0]['amount']\n\n# Calculate group means\nmean_treat = treat_amounts.mean()\nmean_control = control_amounts.mean()\n\n# Plot: Treatment Group\nplt.figure(figsize=(10, 5))\nplt.hist(treat_amounts, bins=50, color='skyblue', edgecolor='black')\nplt.axvline(mean_treat, color='red', linestyle='dashed', linewidth=2, label=f'Mean = ${mean_treat:.2f}')\nplt.title('Histogram of Donation Amounts - Treatment Group')\nplt.xlabel('Donation Amount ($)')\nplt.ylabel('Number of Donors')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Plot: Control Group\nplt.figure(figsize=(10, 5))\nplt.hist(control_amounts, bins=50, color='lightgreen', edgecolor='black')\nplt.axvline(mean_control, color='red', linestyle='dashed', linewidth=2, label=f'Mean = ${mean_control:.2f}')\nplt.title('Histogram of Donation Amounts - Control Group')\nplt.xlabel('Donation Amount ($)')\nplt.ylabel('Number of Donors')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere are the two histograms of donation amounts:\n\nThe first plot shows the distribution for the treatment group, with a red dashed line marking the average donation (around $43.87).\nThe second plot is for the control group, where the average donation is slightly higher (around $45.54)."
  },
  {
    "objectID": "blog/Project 3/hw1_questions.html#simulation-experiment",
    "href": "blog/Project 3/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nnp.random.seed(42)\n\n# Simulate draws from control (p = 0.018) and treatment (p = 0.022)\ncontrol_sim = np.random.binomial(1, 0.018, 100000)\ntreatment_sim = np.random.binomial(1, 0.022, 10000)\n\ncontrol_sample = np.random.choice(control_sim, size=10000, replace=False)\ndiff_vector = treatment_sim - control_sample\ncumulative_avg = np.cumsum(diff_vector) / np.arange(1, len(diff_vector) + 1)\n\n# Plot the cumulative average difference\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, color='blue', linewidth=1, label='Cumulative Average')\nplt.axhline(y=0.004, color='red', linestyle='--', label='True Difference = 0.004')\nplt.title('Simulation of LLN: Cumulative Average of Simulated Differences')\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average Difference')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis plot shows the cumulative average of 10,000 simulated differences in donation behavior between a treatment group (with donation probability 0.022) and a control group (with donation probability 0.018).\n\nThe blue line is the cumulative average of the difference: (treatment draw - control draw) over 10,000 samples.\nThe red dashed line marks the true difference in means, which is 0.004.\n\nAt first, the cumulative average fluctuates as randomness plays a strong role in small samples. But as more samples are added, the average steadily converges toward the true value of 0.004. This is a perfect illustration of the Law of Large Numbers: with enough observations, the sample mean approaches the population mean.\n\n\nCentral Limit Theorem\n\nnp.random.seed(42)\n\n# Simulation parameters\np_control = 0.018\np_treatment = 0.022\nreps = 1000\nsample_sizes = [50, 200, 500, 1000]\n\n# Container for plots\nfig, axes = plt.subplots(2, 2, figsize=(10, 8))\naxes = axes.flatten()\n\n# Perform simulation for each sample size\nfor idx, n in enumerate(sample_sizes):\n    diff_samples = []\n    for _ in range(reps):\n        control_sample = np.random.binomial(1, p_control, n)\n        treatment_sample = np.random.binomial(1, p_treatment, n)\n        diff = treatment_sample.mean() - control_sample.mean()\n        diff_samples.append(diff)\n\n    # Plot histogram\n    axes[idx].hist(diff_samples, bins=30, color='skyblue', edgecolor='black')\n    axes[idx].axvline(x=0, color='red', linestyle='--', label='Zero (Null)')\n    axes[idx].set_title(f\"Sample Size = {n}\")\n    axes[idx].set_xlabel(\"Difference in Means\")\n    axes[idx].set_ylabel(\"Frequency\")\n    axes[idx].legend()\n    axes[idx].grid(True)\n\n# Adjust layout and display\nplt.suptitle(\"Central Limit Theorem: Sampling Distribution of Difference in Means\", fontsize=14)\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])\nplt.show()\n\n\n\n\n\n\n\n\nThe four histograms above show the sampling distribution of the difference in means between treatment and control groups at increasing sample sizes: 50, 200, 500, and 1000. Each histogram is based on 1000 repetitions, where we took samples from Bernoulli distributions with:\n\np = 0.018 for the control group\np = 0.022 for the treatment group\n\nThe red dashed line at 0 represents the null hypothesis (i.e., no difference in means).\n\nInterpretation:\n\nAt n = 50: The distribution is quite spread out and lumpy. Zero falls near the center, but there’s a lot of variation.\nAt n = 200: The shape becomes more bell-like and narrower. The mean is closer to the expected difference.\nAt n = 500 and n = 1000: The distributions are smoother, tighter, and more symmetric. Importantly, zero is no longer centered, but appears more toward the edge of the distribution — showing that the observed differences are less likely under the null.\n\nAs the sample size increases, the sampling distribution becomes increasingly normal in shape due to the Central Limit Theorem. At the same time, the standard error shrinks, meaning the estimates become more precise. This allows us to more confidently detect small differences, such as the true difference in means of 0.004 between the treatment and control groups. Overall, this simulation demonstrates how the Central Limit Theorem enables us to make reliable statistical inferences with large samples, even when the underlying data are binary, such as in a Bernoulli distribution."
  },
  {
    "objectID": "blog/Project 1/index.html",
    "href": "blog/Project 1/index.html",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data\n\n\n\nI analyzed the data\n\nlibrary(tidyverse)\nmtcars |&gt; \n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point()"
  },
  {
    "objectID": "blog/Project 1/index.html#section-1-data",
    "href": "blog/Project 1/index.html#section-1-data",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data"
  },
  {
    "objectID": "blog/Project 1/index.html#section-2-analysis",
    "href": "blog/Project 1/index.html#section-2-analysis",
    "title": "This is Project 1",
    "section": "",
    "text": "I analyzed the data\n\nlibrary(tidyverse)\nmtcars |&gt; \n  ggplot(aes(x = wt, y = mpg)) +\n  geom_point()"
  },
  {
    "objectID": "blog/CW - 1/file1.html",
    "href": "blog/CW - 1/file1.html",
    "title": "Krithika's Website",
    "section": "",
    "text": "import statsmodels.api as sm\nimport pandas as pd\nimport statsmodels.formula.api as smf\n\ndf = pd.read_csv('purchase.csv')\n# Fit a GLM (logistic regression) model\nmodel = smf.glm(formula='purchase ~ idx', data=df, family=sm.families.Binomial()).fit()\n\n# Summary of the model\nmodel_summary = model.summary()\n\n# Calculate confidence interval for the coefficients\nconf_int = model.conf_int()\nconf_int.columns = ['2.5%', '97.5%']\n\nmodel_summary, conf_int\n\n(&lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                  Generalized Linear Model Regression Results                  \n ==============================================================================\n Dep. Variable:               purchase   No. Observations:                 2000\n Model:                            GLM   Df Residuals:                     1998\n Model Family:                Binomial   Df Model:                            1\n Link Function:                  Logit   Scale:                          1.0000\n Method:                          IRLS   Log-Likelihood:                -769.29\n Date:                Fri, 02 May 2025   Deviance:                       1538.6\n Time:                        14:34:34   Pearson chi2:                 2.03e+03\n No. Iterations:                     5   Pseudo R-squ. (CS):            0.06354\n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          z      P&gt;|z|      [0.025      0.975]\n ------------------------------------------------------------------------------\n Intercept     -3.2196      0.160    -20.175      0.000      -3.532      -2.907\n idx            0.0325      0.003     11.142      0.000       0.027       0.038\n ==============================================================================\n \"\"\",\n                2.5%     97.5%\n Intercept -3.532406 -2.906838\n idx        0.026805  0.038249)\n\n\n\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import norm\n\n# Prepare data\nX = df['idx'].values\ny = df['purchase'].values\n\n# Add intercept term\nX_design = np.column_stack((np.ones_like(X), X))\n\n# Define the negative log-likelihood for logistic regression\ndef neg_log_likelihood(beta):\n    linear_pred = np.dot(X_design, beta)\n    log_likelihood = y * linear_pred - np.log(1 + np.exp(linear_pred))\n    return -np.sum(log_likelihood)\n\n# Initial guess\ninitial_beta = np.zeros(X_design.shape[1])\n\n# Minimize the negative log-likelihood\nresult = minimize(neg_log_likelihood, initial_beta, method='BFGS')\n\n# Estimated coefficients\nbeta_hat = result.x\n\n# Hessian and standard errors\nhessian_inv = result.hess_inv\nstandard_errors = np.sqrt(np.diag(hessian_inv))\n\n# 95% Confidence Intervals\nz_score = norm.ppf(0.975)\nci_lower = beta_hat - z_score * standard_errors\nci_upper = beta_hat + z_score * standard_errors\n\n{\n    \"Estimated Coefficients\": beta_hat,\n    \"Standard Errors\": standard_errors,\n    \"95% CI Lower Bound\": ci_lower,\n    \"95% CI Upper Bound\": ci_upper\n}\n\n{'Estimated Coefficients': array([-3.21961997,  0.03252659]),\n 'Standard Errors': array([0.00133333, 0.00119284]),\n '95% CI Lower Bound': array([-3.22223324,  0.03018868]),\n '95% CI Upper Bound': array([-3.21700669,  0.03486451])}"
  },
  {
    "objectID": "blog/Project 4/hw2_questions.html",
    "href": "blog/Project 4/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\nData Description\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.formula.api as smf\nimport matplotlib.pyplot as plt\n\nfile_path = 'blueprinty.csv'\nblueprinty_data = pd.read_csv(file_path)\nprint(blueprinty_data.head())\n\nsummary_stats = blueprinty_data.describe()\nsummary_stats\n\n   patents     region   age  iscustomer\n0        0    Midwest  32.5           0\n1        3  Southwest  37.5           0\n2        4  Northwest  27.0           1\n3        3  Northeast  24.5           0\n4        3  Southwest  37.0           0\n\n\n\n\n\n\n\n\n\npatents\nage\niscustomer\n\n\n\n\ncount\n1500.000000\n1500.000000\n1500.000000\n\n\nmean\n3.684667\n26.357667\n0.320667\n\n\nstd\n2.352500\n7.242528\n0.466889\n\n\nmin\n0.000000\n9.000000\n0.000000\n\n\n25%\n2.000000\n21.000000\n0.000000\n\n\n50%\n3.000000\n26.000000\n0.000000\n\n\n75%\n5.000000\n31.625000\n1.000000\n\n\nmax\n16.000000\n49.000000\n1.000000\n\n\n\n\n\n\n\n\nThe average age of firms is approximately 26 years, with a range from 9 to 49 years.\nThe proportion of firms using Blueprinty’s software is about 32%, with the remaining 68% not using it.\nThe number of patents awarded ranges from 0 to 16, with a mean of 3.68 patents per firm.\n\n\n\n\n\n# Compare histograms of number of patents by customer status\nplt.figure(figsize=(8, 6))\n\n# Plot histogram for customers and non-customers\nblueprinty_data[blueprinty_data['iscustomer'] == 1]['patents'].plot(kind='hist', bins=20, alpha=0.5, color='blue', label='Customer')\nblueprinty_data[blueprinty_data['iscustomer'] == 0]['patents'].plot(kind='hist', bins=20, alpha=0.5, color='red', label='Non-Customer')\nplt.title('Number of Patents by Customer Status')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.legend()\nplt.show()\nplt.close('all')\n# Plot means of patents by customer status\nplt.figure(figsize=(8, 6))\nmean_pats = blueprinty_data.groupby('iscustomer')['patents'].mean()\nax = mean_pats.plot(kind='bar', color=['lightblue', 'lightgreen'])\nax.set_xticks([0, 1])\nax.set_xticklabels(['Non-Customer', 'Customer'], rotation=45)\nplt.title('Average Number of Patents by Customer Status')\nplt.ylabel('Average Number of Patents')\nplt.show()\nplt.tight_layout()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere are the key observations based on the histograms and summary statistics:\n\n\n\nThe histogram for the number of patents awarded shows that both customers (firms using Blueprinty’s software) and non-customers exhibit a similar range of patent counts, but the distribution appears slightly skewed for both groups.\nThere seems to be a higher frequency of firms with 0 to 5 patents, with the non-customer group slightly more concentrated around the lower patent counts.\n\n\n\n\n\nThe average number of patents awarded to non-customers is around 3.68, whereas the average for customers is higher, suggesting that firms using the software may be awarded more patents on average.\n\n\n\n\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\nregion_counts = blueprinty_data.groupby(['iscustomer', 'region']).size().unstack().fillna(0)\n\n# Display summary statistics for age by customer status\nage_stats_by_customer = blueprinty_data.groupby('iscustomer')['age'].describe()\nprint(age_stats_by_customer)\n\n# Plot the region distribution for customers vs non-customers\nplt.figure(figsize=(10, 6))\nregion_counts.T.plot(kind='bar', stacked=True)\nplt.title('Region Distribution by Customer Status')\nplt.xlabel('Region')\nplt.ylabel('Number of Firms')\nplt.xticks(rotation=45)\nplt.legend(title='Customer Status', labels=['Non-Customer', 'Customer'])\nplt.tight_layout()\nplt.show()\nplt.close('all')\n\n# Plot age distributions for customers and non-customers\nplt.figure(figsize=(8, 6))\nblueprinty_data[blueprinty_data['iscustomer'] == 1]['age'].plot(kind='hist', bins=20, alpha=0.5, color='blue', label='Customer')\nblueprinty_data[blueprinty_data['iscustomer'] == 0]['age'].plot(kind='hist', bins=20, alpha=0.5, color='red', label='Non-Customer')\n\nplt.title('Age Distribution by Customer Status')\nplt.xlabel('Age (Years)')\nplt.ylabel('Frequency')\nplt.legend()\nplt.tight_layout()\nplt.show()\nplt.close('all')\n\n             count       mean       std   min   25%   50%    75%   max\niscustomer                                                            \n0           1019.0  26.101570  6.945426   9.0  21.0  25.5  31.25  47.5\n1            481.0  26.900208  7.814678  10.0  20.5  26.5  32.50  49.0\n\n\n&lt;Figure size 960x576 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe regional distribution of firms shows that the number of customers (firms using Blueprinty’s software) and non-customers varies by region. There may be some regional concentration of Blueprinty’s customers in certain areas. This suggests that the decision to use the software might be influenced by the firm’s location.\n\n\n\n\n\nThe average age of firms using Blueprinty’s software is slightly higher (mean age = 26.9 years) compared to non-customers (mean age = 26.1 years).\nBoth customer and non-customer firms have a similar range of ages, but customers tend to be slightly older on average. The age distribution is fairly similar, with a slight tendency for customers to be a bit older.\n\nThese differences suggest that age and region may be systematic factors influencing the decision to use Blueprinty’s software. Accounting for these variables in the model would help isolate the effect of the software on the number of patents awarded.\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nThe mathematical likelihood for _ \\(Y \\sim \\text{Poisson}(\\lambda)\\) is given by the following formula:\n\\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\n\n𝑌 is the observed number of patents awarded (the outcome variable),\nλ is the expected number of patents awarded (which depends on the independent variables in the model, such as age and software usage),\n𝑌! is the factorial of 𝑌.\n\nLog Liklihood Function:\n\\(log L(\\lambda) = Σ (Yi * log(\\lambda) - \\lambda - log(Yi!))\\)\n\nfrom math import factorial\n\ndef poisson_loglikelihood(lambda_, Y):\n    \"\"\"\n    Log-likelihood function for Poisson regression.\n    \n    lambda_ : float or array-like\n        The expected number of events (patents awarded).\n        \n    Y : array-like\n        Observed number of patents awarded by each firm.\n    \n    Returns\n    -------\n    log_likelihood : float\n        The log-likelihood for the Poisson model.\n    \"\"\"\n    log_likelihood = np.sum(Y * np.log(lambda_) - lambda_ - np.log([factorial(int(y)) for y in Y]))\n    return log_likelihood\n\n\nY = blueprinty_data['patents'].values\n\n# Generate a range of lambda values\nlambda_values = np.linspace(0.1, 10, 100)\n\n# Calculate log-likelihood for each lambda using the observed data\nlog_likelihood_values = [poisson_loglikelihood(l, Y) for l in lambda_values]\n\n# Plotting the log-likelihood\nplt.figure(figsize=(8, 6))\nplt.plot(lambda_values, log_likelihood_values, label='Log-Likelihood', color='blue')\nplt.title('Log-Likelihood for Different Lambda Values (Observed Patents)')\nplt.xlabel('Lambda')\nplt.ylabel('Log-Likelihood')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nWe can observe that the log-likelihood increases until it reaches its maximum and then starts to decrease. The peak corresponds to the 𝜆 that best fits the observed data.\n\n\nThe log-likelihood function for the Poisson distribution is:\n\\(\\log L(\\lambda) = \\sum_{i=1}^{n} \\left( Y_i \\log(\\lambda) - \\lambda - \\log(Y_i!) \\right)\\)\nTaking the first derivative of this log-likelihood function with respect to 𝜆 and setting it equal to zero will help us find the maximum likelihood estimate (MLE) for 𝜆. Derivative:\n\\(\\frac{d}{d\\lambda} \\log L(\\lambda) = \\sum_{i=1}^{n} \\left( \\frac{Y_i}{\\lambda} - 1 \\right)\\)\nSetting this derivative equal to zero to find the critical point:\n\\(\\sum_{i=1}^{n} \\left( \\frac{Y_i}{\\lambda} - 1 \\right) = 0\\)\nSolving for 𝜆, we get:\n\\(\\lambda_{\\text{MLE}} = \\frac{\\sum_{i=1}^{n} Y_i}{n} = \\bar{Y}\\)\nThis shows that the MLE for 𝜆 is simply the mean of the observed number of patents 𝑌ˉ, which “feels right” because the mean of a Poisson distribution is 𝜆.\n\n\n\n\nfrom scipy.optimize import minimize\n\n# Define the negative log-likelihood (since we are minimizing)\ndef neg_poisson_loglikelihood(lambda_, Y):\n    return -poisson_loglikelihood(lambda_, Y)\n\n# Use scipy's minimize function to find the MLE\nresult = minimize(neg_poisson_loglikelihood, x0=1, args=(Y,), bounds=[(0.1, 10)])\n\n# Extract the MLE\nlambda_mle = result.x[0]\nprint(f\"The MLE for lambda is: {round(lambda_mle,4)}\")\n\nThe MLE for lambda is: 3.6847\n\n\nThe Maximum Likelihood Estimate (MLE) for 𝜆, based on the data, is approximately 3.6846. This means that the best estimate for the expected number of patents awarded, according to the Poisson distribution and the data provided, is about 3.6846 patents per firm.\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\n\nWe will update the log-likelihood function to take into account the covariate matrix 𝑋 and the parameter vector 𝛽. The likelihood for each observation 𝑖 will be:\n\\(f(Y|\\beta, X) = \\sum_{i=1}^{n} \\frac{\\lambda_i^{Y_i} e^{-\\lambda_i}}{Y_i!}\\)\nWhere 𝜆𝑖 = exp⁡(𝑋𝑖′𝛽).\nThe log-likelihood for the Poisson regression model is:\n\\(\\log L(\\beta) = \\sum_{i=1}^{n} \\left( Y_i X_i' \\beta - e^{X_i' \\beta} - \\log(Y_i!) \\right)\\)\nHere’s the updated Poisson regression likelihood function\n\nimport numpy as np\nfrom scipy.special import factorial\nimport numpy as np\nimport pandas as pd\nimport scipy as sp\nfrom statsmodels.tools.tools import add_constant\nimport statsmodels.api as sm\nfrom scipy.special import factorial, gammaln\n\n# Define the Poisson regression log-likelihood function\ndef poisson_regression_loglikelihood(beta, Y, X):\n    beta = np.asarray(beta, dtype=float)\n    Xb = X @ beta\n    Xb = np.clip(Xb, -20, 20)  # Prevent overflow\n    lambda_i = np.array([math.exp(val) for val in Xb])  # Use math.exp for robustness\n    return -(np.sum(-lambda_i + Y * Xb - gammaln(Y + 1)))\n\nThis updated function models the number of patents as a function of firm characteristics using the exponential link function, and it computes the log-likelihood for the Poisson regression model.\n\nimport math\n\n# Create variables\nblueprinty_data[\"age_centered\"] = blueprinty_data[\"age\"] - blueprinty_data[\"age\"].mean()\nblueprinty_data[\"age_sq\"] = blueprinty_data[\"age_centered\"] ** 2\nregion_dummies = pd.get_dummies(blueprinty_data[\"region\"], prefix=\"region\", drop_first=True)\n\n# Construct design matrix\nX = pd.concat([\n    pd.Series(1, index=blueprinty_data.index, name=\"intercept\"),\n    blueprinty_data[[\"age_centered\", \"age_sq\", \"iscustomer\"]],\n    region_dummies\n], axis=1)\n\nX_matrix = X.astype(float).values\nY = blueprinty_data[\"patents\"].astype(float).values\n\n# Initial guess for beta (starting values for the optimization)\ninitial_beta = np.zeros(X_matrix.shape[1])\n# Use scipy's minimize function to find the MLE (we are minimizing the negative log-likelihood)\nresult = sp.optimize.minimize(poisson_regression_loglikelihood, initial_beta, args=(Y, X_matrix), method='BFGS')\n# Extract the MLE of the coefficients\nbeta_hat = result.x\n# Calculate the Hessian (second derivative of the log-likelihood)\nhessian = result.hess_inv\n# Compute the standard errors (sqrt of diagonal of the inverse Hessian)\nstd_errors = np.sqrt(np.diag(hessian))\n# Create a DataFrame with coefficients and standard errors\ncoef_table = pd.DataFrame({\n    'Coefficient': beta_hat,\n    'Standard Error': std_errors\n}, index=X.columns)\ncoef_table\n\n\n\n\n\n\n\n\nCoefficient\nStandard Error\n\n\n\n\nintercept\n1.344676\n0.033292\n\n\nage_centered\n-0.007970\n0.010645\n\n\nage_sq\n-0.002970\n0.000358\n\n\niscustomer\n0.207591\n0.033573\n\n\nregion_Northeast\n0.029170\n0.034616\n\n\nregion_Northwest\n-0.017575\n0.036664\n\n\nregion_South\n0.056561\n0.137314\n\n\nregion_Southwest\n0.050576\n0.095147\n\n\n\n\n\n\n\n\n\n\n\nimport statsmodels.api as sm\n\n# Fit the Poisson regression model using statsmodels' GLM\nglm_model = sm.GLM(Y, X_matrix, family=sm.families.Poisson(), link=sm.families.links.log()).fit()\n\n# Display the summary of the GLM model\nprint(glm_model.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                      y   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Wed, 07 May 2025   Deviance:                       2143.3\nTime:                        20:04:06   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          1.3447      0.038     35.059      0.000       1.270       1.420\nx1            -0.0080      0.002     -3.843      0.000      -0.012      -0.004\nx2            -0.0030      0.000    -11.513      0.000      -0.003      -0.002\nx3             0.2076      0.031      6.719      0.000       0.147       0.268\nx4             0.0292      0.044      0.669      0.504      -0.056       0.115\nx5            -0.0176      0.054     -0.327      0.744      -0.123       0.088\nx6             0.0566      0.053      1.074      0.283      -0.047       0.160\nx7             0.0506      0.047      1.072      0.284      -0.042       0.143\n==============================================================================\n\n\n/Users/krithikasuwarna/Library/Python/3.9/lib/python/site-packages/statsmodels/genmod/families/links.py:13: FutureWarning: The log link alias is deprecated. Use Log instead. The log link alias will be removed after the 0.15.0 release.\n  warnings.warn(\n/Users/krithikasuwarna/Library/Python/3.9/lib/python/site-packages/statsmodels/base/model.py:130: ValueWarning: unknown kwargs ['link']\n  warnings.warn(msg, ValueWarning)\n\n\nThe results of the Poisson regression model, shown in the table above, present the estimated coefficients and their corresponding standard errors. These results are obtained after estimating the model using Maximum Likelihood Estimation (MLE) and calculating the Hessian matrix for the standard errors.\n\n\n\n\nIntercept:\n\n\nThe intercept term has a coefficient of 1.3447, which represents the log of the expected number of patents awarded for a firm with average age, no age squared, and not using Blueprinty’s software. The standard error is 0.0383, suggesting this estimate is fairly precise.\n\n\nAge-Centered:\n\n\nThe coefficient for age_centered is -0.00797, which implies that, holding all else constant, a one-year increase in age (relative to the average firm age) slightly decreases the expected number of patents. The standard error (0.00207) indicates this effect is statistically significant.\n\n\nAge Squared:\n\n\nThe age_sq coefficient is -0.00297, suggesting a quadratic relationship with age. As age increases, the number of patents decreases, but the effect diminishes at higher ages (due to the negative coefficient on age squared). The standard error of 0.00025 is small, indicating a precise estimate.\n\n\nIsCustomer:\n\n\nThe coefficient for iscustomer is 0.20759, meaning firms using Blueprinty’s software (iscustomer = 1) are expected to receive approximately 21% more patents than non-customers, controlling for other factors like age and region. The standard error (0.0309) suggests that this result is statistically significant.\n\n\nRegions:\n\n\nThe coefficients for the region variables (relative to the base region) show regional effects on the expected number of patents. For example, region_Northeast has a coefficient of 0.02917, meaning firms in the Northeast region tend to have slightly more patents, compared to firms in the base region. The standard errors for the regional coefficients range from 0.0436 to 0.0538.\n\n\n\nThe model suggests that Blueprinty’s software usage has a statistically significant positive effect on the number of patents awarded, as firms using the software are predicted to have more patents. Additionally, age, age squared, and region also influence patent counts, with older firms tending to have fewer patents. These results could be used to support the claim that Blueprinty’s software has a positive impact on patent success.\n\n\n\n\n\n# Create two new datasets: X_0 (customers=0) and X_1 (customers=1)\nX_0 = X.copy()\nX_0['iscustomer'] = 0  # Set iscustomer to 0 for all rows (non-customers)\nX_0 = X_0.astype(float).values\nX_1 = X.copy()\nX_1['iscustomer'] = 1  # Set iscustomer to 1 for all rows (customers)\nX_1 = X_1.astype(float).values\n\n# Predict the number of patents for both X_0 and X_1 using the fitted model\ny_pred_0 = glm_model.predict(X_0)\ny_pred_1 = glm_model.predict(X_1)\n\n# Calculate the difference in predicted patents between customers and non-customers\ny_diff = y_pred_1 - y_pred_0\n\n# Compute the average difference\navg_diff = np.mean(y_diff)\n\n# Display the result\nprint(f\"The average effect of being a customer on the number of patents is: {round(avg_diff, 4)}\")\n\nThe average effect of being a customer on the number of patents is: 0.7928\n\n\nThe analysis of the effect of Blueprinty’s software on the number of patents awarded to firms suggests a positive impact. After fitting a Poisson regression model and computing the average difference in predicted patents for firms using the software (customers) versus those not using it (non-customers), the results indicate that customers, on average, receive 0.79 more patents than non-customers.\nThis suggests that Blueprinty’s software is associated with an increase in the number of patents awarded, controlling for factors such as firm age, age squared, and regional location. The software appears to have a beneficial effect on patent success, supporting the marketing claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\nThese findings provide valuable insight into the potential advantages of using Blueprinty’s software and its role in improving the patent outcomes for engineering firms."
  },
  {
    "objectID": "blog/Project 4/hw2_questions.html#blueprinty-case-study",
    "href": "blog/Project 4/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\nData Description\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.formula.api as smf\nimport matplotlib.pyplot as plt\n\nfile_path = 'blueprinty.csv'\nblueprinty_data = pd.read_csv(file_path)\nprint(blueprinty_data.head())\n\nsummary_stats = blueprinty_data.describe()\nsummary_stats\n\n   patents     region   age  iscustomer\n0        0    Midwest  32.5           0\n1        3  Southwest  37.5           0\n2        4  Northwest  27.0           1\n3        3  Northeast  24.5           0\n4        3  Southwest  37.0           0\n\n\n\n\n\n\n\n\n\npatents\nage\niscustomer\n\n\n\n\ncount\n1500.000000\n1500.000000\n1500.000000\n\n\nmean\n3.684667\n26.357667\n0.320667\n\n\nstd\n2.352500\n7.242528\n0.466889\n\n\nmin\n0.000000\n9.000000\n0.000000\n\n\n25%\n2.000000\n21.000000\n0.000000\n\n\n50%\n3.000000\n26.000000\n0.000000\n\n\n75%\n5.000000\n31.625000\n1.000000\n\n\nmax\n16.000000\n49.000000\n1.000000\n\n\n\n\n\n\n\n\nThe average age of firms is approximately 26 years, with a range from 9 to 49 years.\nThe proportion of firms using Blueprinty’s software is about 32%, with the remaining 68% not using it.\nThe number of patents awarded ranges from 0 to 16, with a mean of 3.68 patents per firm.\n\n\n\n\n\n# Compare histograms of number of patents by customer status\nplt.figure(figsize=(8, 6))\n\n# Plot histogram for customers and non-customers\nblueprinty_data[blueprinty_data['iscustomer'] == 1]['patents'].plot(kind='hist', bins=20, alpha=0.5, color='blue', label='Customer')\nblueprinty_data[blueprinty_data['iscustomer'] == 0]['patents'].plot(kind='hist', bins=20, alpha=0.5, color='red', label='Non-Customer')\nplt.title('Number of Patents by Customer Status')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.legend()\nplt.show()\nplt.close('all')\n# Plot means of patents by customer status\nplt.figure(figsize=(8, 6))\nmean_pats = blueprinty_data.groupby('iscustomer')['patents'].mean()\nax = mean_pats.plot(kind='bar', color=['lightblue', 'lightgreen'])\nax.set_xticks([0, 1])\nax.set_xticklabels(['Non-Customer', 'Customer'], rotation=45)\nplt.title('Average Number of Patents by Customer Status')\nplt.ylabel('Average Number of Patents')\nplt.show()\nplt.tight_layout()\nplt.close('all')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere are the key observations based on the histograms and summary statistics:\n\n\n\nThe histogram for the number of patents awarded shows that both customers (firms using Blueprinty’s software) and non-customers exhibit a similar range of patent counts, but the distribution appears slightly skewed for both groups.\nThere seems to be a higher frequency of firms with 0 to 5 patents, with the non-customer group slightly more concentrated around the lower patent counts.\n\n\n\n\n\nThe average number of patents awarded to non-customers is around 3.68, whereas the average for customers is higher, suggesting that firms using the software may be awarded more patents on average.\n\n\n\n\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\nregion_counts = blueprinty_data.groupby(['iscustomer', 'region']).size().unstack().fillna(0)\n\n# Display summary statistics for age by customer status\nage_stats_by_customer = blueprinty_data.groupby('iscustomer')['age'].describe()\nprint(age_stats_by_customer)\n\n# Plot the region distribution for customers vs non-customers\nplt.figure(figsize=(10, 6))\nregion_counts.T.plot(kind='bar', stacked=True)\nplt.title('Region Distribution by Customer Status')\nplt.xlabel('Region')\nplt.ylabel('Number of Firms')\nplt.xticks(rotation=45)\nplt.legend(title='Customer Status', labels=['Non-Customer', 'Customer'])\nplt.tight_layout()\nplt.show()\nplt.close('all')\n\n# Plot age distributions for customers and non-customers\nplt.figure(figsize=(8, 6))\nblueprinty_data[blueprinty_data['iscustomer'] == 1]['age'].plot(kind='hist', bins=20, alpha=0.5, color='blue', label='Customer')\nblueprinty_data[blueprinty_data['iscustomer'] == 0]['age'].plot(kind='hist', bins=20, alpha=0.5, color='red', label='Non-Customer')\n\nplt.title('Age Distribution by Customer Status')\nplt.xlabel('Age (Years)')\nplt.ylabel('Frequency')\nplt.legend()\nplt.tight_layout()\nplt.show()\nplt.close('all')\n\n             count       mean       std   min   25%   50%    75%   max\niscustomer                                                            \n0           1019.0  26.101570  6.945426   9.0  21.0  25.5  31.25  47.5\n1            481.0  26.900208  7.814678  10.0  20.5  26.5  32.50  49.0\n\n\n&lt;Figure size 960x576 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe regional distribution of firms shows that the number of customers (firms using Blueprinty’s software) and non-customers varies by region. There may be some regional concentration of Blueprinty’s customers in certain areas. This suggests that the decision to use the software might be influenced by the firm’s location.\n\n\n\n\n\nThe average age of firms using Blueprinty’s software is slightly higher (mean age = 26.9 years) compared to non-customers (mean age = 26.1 years).\nBoth customer and non-customer firms have a similar range of ages, but customers tend to be slightly older on average. The age distribution is fairly similar, with a slight tendency for customers to be a bit older.\n\nThese differences suggest that age and region may be systematic factors influencing the decision to use Blueprinty’s software. Accounting for these variables in the model would help isolate the effect of the software on the number of patents awarded.\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nThe mathematical likelihood for _ \\(Y \\sim \\text{Poisson}(\\lambda)\\) is given by the following formula:\n\\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\n\n𝑌 is the observed number of patents awarded (the outcome variable),\nλ is the expected number of patents awarded (which depends on the independent variables in the model, such as age and software usage),\n𝑌! is the factorial of 𝑌.\n\nLog Liklihood Function:\n\\(log L(\\lambda) = Σ (Yi * log(\\lambda) - \\lambda - log(Yi!))\\)\n\nfrom math import factorial\n\ndef poisson_loglikelihood(lambda_, Y):\n    \"\"\"\n    Log-likelihood function for Poisson regression.\n    \n    lambda_ : float or array-like\n        The expected number of events (patents awarded).\n        \n    Y : array-like\n        Observed number of patents awarded by each firm.\n    \n    Returns\n    -------\n    log_likelihood : float\n        The log-likelihood for the Poisson model.\n    \"\"\"\n    log_likelihood = np.sum(Y * np.log(lambda_) - lambda_ - np.log([factorial(int(y)) for y in Y]))\n    return log_likelihood\n\n\nY = blueprinty_data['patents'].values\n\n# Generate a range of lambda values\nlambda_values = np.linspace(0.1, 10, 100)\n\n# Calculate log-likelihood for each lambda using the observed data\nlog_likelihood_values = [poisson_loglikelihood(l, Y) for l in lambda_values]\n\n# Plotting the log-likelihood\nplt.figure(figsize=(8, 6))\nplt.plot(lambda_values, log_likelihood_values, label='Log-Likelihood', color='blue')\nplt.title('Log-Likelihood for Different Lambda Values (Observed Patents)')\nplt.xlabel('Lambda')\nplt.ylabel('Log-Likelihood')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nWe can observe that the log-likelihood increases until it reaches its maximum and then starts to decrease. The peak corresponds to the 𝜆 that best fits the observed data.\n\n\nThe log-likelihood function for the Poisson distribution is:\n\\(\\log L(\\lambda) = \\sum_{i=1}^{n} \\left( Y_i \\log(\\lambda) - \\lambda - \\log(Y_i!) \\right)\\)\nTaking the first derivative of this log-likelihood function with respect to 𝜆 and setting it equal to zero will help us find the maximum likelihood estimate (MLE) for 𝜆. Derivative:\n\\(\\frac{d}{d\\lambda} \\log L(\\lambda) = \\sum_{i=1}^{n} \\left( \\frac{Y_i}{\\lambda} - 1 \\right)\\)\nSetting this derivative equal to zero to find the critical point:\n\\(\\sum_{i=1}^{n} \\left( \\frac{Y_i}{\\lambda} - 1 \\right) = 0\\)\nSolving for 𝜆, we get:\n\\(\\lambda_{\\text{MLE}} = \\frac{\\sum_{i=1}^{n} Y_i}{n} = \\bar{Y}\\)\nThis shows that the MLE for 𝜆 is simply the mean of the observed number of patents 𝑌ˉ, which “feels right” because the mean of a Poisson distribution is 𝜆.\n\n\n\n\nfrom scipy.optimize import minimize\n\n# Define the negative log-likelihood (since we are minimizing)\ndef neg_poisson_loglikelihood(lambda_, Y):\n    return -poisson_loglikelihood(lambda_, Y)\n\n# Use scipy's minimize function to find the MLE\nresult = minimize(neg_poisson_loglikelihood, x0=1, args=(Y,), bounds=[(0.1, 10)])\n\n# Extract the MLE\nlambda_mle = result.x[0]\nprint(f\"The MLE for lambda is: {round(lambda_mle,4)}\")\n\nThe MLE for lambda is: 3.6847\n\n\nThe Maximum Likelihood Estimate (MLE) for 𝜆, based on the data, is approximately 3.6846. This means that the best estimate for the expected number of patents awarded, according to the Poisson distribution and the data provided, is about 3.6846 patents per firm.\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\n\nWe will update the log-likelihood function to take into account the covariate matrix 𝑋 and the parameter vector 𝛽. The likelihood for each observation 𝑖 will be:\n\\(f(Y|\\beta, X) = \\sum_{i=1}^{n} \\frac{\\lambda_i^{Y_i} e^{-\\lambda_i}}{Y_i!}\\)\nWhere 𝜆𝑖 = exp⁡(𝑋𝑖′𝛽).\nThe log-likelihood for the Poisson regression model is:\n\\(\\log L(\\beta) = \\sum_{i=1}^{n} \\left( Y_i X_i' \\beta - e^{X_i' \\beta} - \\log(Y_i!) \\right)\\)\nHere’s the updated Poisson regression likelihood function\n\nimport numpy as np\nfrom scipy.special import factorial\nimport numpy as np\nimport pandas as pd\nimport scipy as sp\nfrom statsmodels.tools.tools import add_constant\nimport statsmodels.api as sm\nfrom scipy.special import factorial, gammaln\n\n# Define the Poisson regression log-likelihood function\ndef poisson_regression_loglikelihood(beta, Y, X):\n    beta = np.asarray(beta, dtype=float)\n    Xb = X @ beta\n    Xb = np.clip(Xb, -20, 20)  # Prevent overflow\n    lambda_i = np.array([math.exp(val) for val in Xb])  # Use math.exp for robustness\n    return -(np.sum(-lambda_i + Y * Xb - gammaln(Y + 1)))\n\nThis updated function models the number of patents as a function of firm characteristics using the exponential link function, and it computes the log-likelihood for the Poisson regression model.\n\nimport math\n\n# Create variables\nblueprinty_data[\"age_centered\"] = blueprinty_data[\"age\"] - blueprinty_data[\"age\"].mean()\nblueprinty_data[\"age_sq\"] = blueprinty_data[\"age_centered\"] ** 2\nregion_dummies = pd.get_dummies(blueprinty_data[\"region\"], prefix=\"region\", drop_first=True)\n\n# Construct design matrix\nX = pd.concat([\n    pd.Series(1, index=blueprinty_data.index, name=\"intercept\"),\n    blueprinty_data[[\"age_centered\", \"age_sq\", \"iscustomer\"]],\n    region_dummies\n], axis=1)\n\nX_matrix = X.astype(float).values\nY = blueprinty_data[\"patents\"].astype(float).values\n\n# Initial guess for beta (starting values for the optimization)\ninitial_beta = np.zeros(X_matrix.shape[1])\n# Use scipy's minimize function to find the MLE (we are minimizing the negative log-likelihood)\nresult = sp.optimize.minimize(poisson_regression_loglikelihood, initial_beta, args=(Y, X_matrix), method='BFGS')\n# Extract the MLE of the coefficients\nbeta_hat = result.x\n# Calculate the Hessian (second derivative of the log-likelihood)\nhessian = result.hess_inv\n# Compute the standard errors (sqrt of diagonal of the inverse Hessian)\nstd_errors = np.sqrt(np.diag(hessian))\n# Create a DataFrame with coefficients and standard errors\ncoef_table = pd.DataFrame({\n    'Coefficient': beta_hat,\n    'Standard Error': std_errors\n}, index=X.columns)\ncoef_table\n\n\n\n\n\n\n\n\nCoefficient\nStandard Error\n\n\n\n\nintercept\n1.344676\n0.033292\n\n\nage_centered\n-0.007970\n0.010645\n\n\nage_sq\n-0.002970\n0.000358\n\n\niscustomer\n0.207591\n0.033573\n\n\nregion_Northeast\n0.029170\n0.034616\n\n\nregion_Northwest\n-0.017575\n0.036664\n\n\nregion_South\n0.056561\n0.137314\n\n\nregion_Southwest\n0.050576\n0.095147\n\n\n\n\n\n\n\n\n\n\n\nimport statsmodels.api as sm\n\n# Fit the Poisson regression model using statsmodels' GLM\nglm_model = sm.GLM(Y, X_matrix, family=sm.families.Poisson(), link=sm.families.links.log()).fit()\n\n# Display the summary of the GLM model\nprint(glm_model.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                      y   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Wed, 07 May 2025   Deviance:                       2143.3\nTime:                        20:04:06   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          1.3447      0.038     35.059      0.000       1.270       1.420\nx1            -0.0080      0.002     -3.843      0.000      -0.012      -0.004\nx2            -0.0030      0.000    -11.513      0.000      -0.003      -0.002\nx3             0.2076      0.031      6.719      0.000       0.147       0.268\nx4             0.0292      0.044      0.669      0.504      -0.056       0.115\nx5            -0.0176      0.054     -0.327      0.744      -0.123       0.088\nx6             0.0566      0.053      1.074      0.283      -0.047       0.160\nx7             0.0506      0.047      1.072      0.284      -0.042       0.143\n==============================================================================\n\n\n/Users/krithikasuwarna/Library/Python/3.9/lib/python/site-packages/statsmodels/genmod/families/links.py:13: FutureWarning: The log link alias is deprecated. Use Log instead. The log link alias will be removed after the 0.15.0 release.\n  warnings.warn(\n/Users/krithikasuwarna/Library/Python/3.9/lib/python/site-packages/statsmodels/base/model.py:130: ValueWarning: unknown kwargs ['link']\n  warnings.warn(msg, ValueWarning)\n\n\nThe results of the Poisson regression model, shown in the table above, present the estimated coefficients and their corresponding standard errors. These results are obtained after estimating the model using Maximum Likelihood Estimation (MLE) and calculating the Hessian matrix for the standard errors.\n\n\n\n\nIntercept:\n\n\nThe intercept term has a coefficient of 1.3447, which represents the log of the expected number of patents awarded for a firm with average age, no age squared, and not using Blueprinty’s software. The standard error is 0.0383, suggesting this estimate is fairly precise.\n\n\nAge-Centered:\n\n\nThe coefficient for age_centered is -0.00797, which implies that, holding all else constant, a one-year increase in age (relative to the average firm age) slightly decreases the expected number of patents. The standard error (0.00207) indicates this effect is statistically significant.\n\n\nAge Squared:\n\n\nThe age_sq coefficient is -0.00297, suggesting a quadratic relationship with age. As age increases, the number of patents decreases, but the effect diminishes at higher ages (due to the negative coefficient on age squared). The standard error of 0.00025 is small, indicating a precise estimate.\n\n\nIsCustomer:\n\n\nThe coefficient for iscustomer is 0.20759, meaning firms using Blueprinty’s software (iscustomer = 1) are expected to receive approximately 21% more patents than non-customers, controlling for other factors like age and region. The standard error (0.0309) suggests that this result is statistically significant.\n\n\nRegions:\n\n\nThe coefficients for the region variables (relative to the base region) show regional effects on the expected number of patents. For example, region_Northeast has a coefficient of 0.02917, meaning firms in the Northeast region tend to have slightly more patents, compared to firms in the base region. The standard errors for the regional coefficients range from 0.0436 to 0.0538.\n\n\n\nThe model suggests that Blueprinty’s software usage has a statistically significant positive effect on the number of patents awarded, as firms using the software are predicted to have more patents. Additionally, age, age squared, and region also influence patent counts, with older firms tending to have fewer patents. These results could be used to support the claim that Blueprinty’s software has a positive impact on patent success.\n\n\n\n\n\n# Create two new datasets: X_0 (customers=0) and X_1 (customers=1)\nX_0 = X.copy()\nX_0['iscustomer'] = 0  # Set iscustomer to 0 for all rows (non-customers)\nX_0 = X_0.astype(float).values\nX_1 = X.copy()\nX_1['iscustomer'] = 1  # Set iscustomer to 1 for all rows (customers)\nX_1 = X_1.astype(float).values\n\n# Predict the number of patents for both X_0 and X_1 using the fitted model\ny_pred_0 = glm_model.predict(X_0)\ny_pred_1 = glm_model.predict(X_1)\n\n# Calculate the difference in predicted patents between customers and non-customers\ny_diff = y_pred_1 - y_pred_0\n\n# Compute the average difference\navg_diff = np.mean(y_diff)\n\n# Display the result\nprint(f\"The average effect of being a customer on the number of patents is: {round(avg_diff, 4)}\")\n\nThe average effect of being a customer on the number of patents is: 0.7928\n\n\nThe analysis of the effect of Blueprinty’s software on the number of patents awarded to firms suggests a positive impact. After fitting a Poisson regression model and computing the average difference in predicted patents for firms using the software (customers) versus those not using it (non-customers), the results indicate that customers, on average, receive 0.79 more patents than non-customers.\nThis suggests that Blueprinty’s software is associated with an increase in the number of patents awarded, controlling for factors such as firm age, age squared, and regional location. The software appears to have a beneficial effect on patent success, supporting the marketing claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\nThese findings provide valuable insight into the potential advantages of using Blueprinty’s software and its role in improving the patent outcomes for engineering firms."
  },
  {
    "objectID": "blog/Project 4/hw2_questions.html#airbnb-case-study",
    "href": "blog/Project 4/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\n\n\nLoad and Explore the Data\nWe’ll start by loading the dataset and examining the first few rows to get an understanding of the variables.\n\n# Load the dataset\nfile_path = 'airbnb.csv'\nairbnb_data = pd.read_csv(file_path)\n\n# Display the first few rows of the dataset\nairbnb_data.head()\n\n\n\n\n\n\n\n\nUnnamed: 0\nid\ndays\nlast_scraped\nhost_since\nroom_type\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\ninstant_bookable\n\n\n\n\n0\n1\n2515\n3130\n4/2/2017\n9/6/2008\nPrivate room\n1.0\n1.0\n59\n150\n9.0\n9.0\n9.0\nf\n\n\n1\n2\n2595\n3127\n4/2/2017\n9/9/2008\nEntire home/apt\n1.0\n0.0\n230\n20\n9.0\n10.0\n9.0\nf\n\n\n2\n3\n3647\n3050\n4/2/2017\n11/25/2008\nPrivate room\n1.0\n1.0\n150\n0\nNaN\nNaN\nNaN\nf\n\n\n3\n4\n3831\n3038\n4/2/2017\n12/7/2008\nEntire home/apt\n1.0\n1.0\n89\n116\n9.0\n9.0\n9.0\nf\n\n\n4\n5\n4611\n3012\n4/2/2017\n1/2/2009\nPrivate room\nNaN\n1.0\n39\n93\n9.0\n8.0\n9.0\nt\n\n\n\n\n\n\n\n\n\nExploratory Data Analysis (EDA)\nWe will proceed with some basic exploratory data analysis (EDA), such as summary statistics, visualizations for the distribution of key variables like price, number_of_reviews, and room_type.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# Limit extreme price values (e.g., remove prices above the 99th percentile)\nprice_upper_limit = np.percentile(airbnb_data['price'], 99)\nfiltered_price_data = airbnb_data[airbnb_data['price'] &lt;= price_upper_limit]\n\n# Plot price distribution with limited values\nplt.figure(figsize=(10, 6))\nsns.histplot(filtered_price_data['price'], kde=True, color='blue', bins=50)\nplt.title('Price Distribution')\nplt.xlabel('Price')\nplt.ylabel('Frequency')\nplt.show()\n\n# Limit number of reviews to values up to 100\nfiltered_reviews_data = airbnb_data[airbnb_data['number_of_reviews'] &lt;= 100]\n\n# Plot number of reviews distribution with a log scale on the y-axis\nplt.figure(figsize=(10, 6))\nsns.histplot(filtered_reviews_data['number_of_reviews'], kde=True, color='green', bins=50)\nplt.title('Number of Reviews Distribution (Up to 100) with Log Y-Axis')\nplt.xlabel('Number of Reviews')\nplt.ylabel('Frequency (Log Scale)')\nplt.yscale('log')  # Apply log scale to the y-axis\nplt.show()\n\n# Room Type Distribution by Price (Boxplot)\nplt.figure(figsize=(10, 6))\nsns.boxplot(data=airbnb_data, x='room_type', y='price', palette='Set2')\nplt.title('Room Type Distribution by Price')\nplt.xlabel('Room Type')\nplt.ylabel('Price')\nplt.yscale('log')  # Log scale for price to handle large differences in price values\nplt.show()\n\n# Number of Reviews by Room Type (Bar Plot)\nplt.figure(figsize=(10, 6))\nsns.barplot(x='room_type', y='number_of_reviews', data=airbnb_data, palette='Set2')\nplt.title('Total Number of Reviews by Room Type')\nplt.xlabel('Room Type')\nplt.ylabel('Total Number of Reviews')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/var/folders/6t/lkwvpnj13875sbb8yqc9c6pc0000gn/T/ipykernel_32241/3156423553.py:31: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.boxplot(data=airbnb_data, x='room_type', y='price', palette='Set2')\n\n\n\n\n\n\n\n\n\n/var/folders/6t/lkwvpnj13875sbb8yqc9c6pc0000gn/T/ipykernel_32241/3156423553.py:40: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='room_type', y='number_of_reviews', data=airbnb_data, palette='Set2')\n\n\n\n\n\n\n\n\n\n\n\nData Cleaning\nNext, we’ll check for any missing values in relevant columns such as number_of_reviews, price, bathrooms, and bedrooms. We will handle missing values appropriately (either by dropping or imputing).\n\n# Check for missing values in relevant columns\nrelevant_columns = ['number_of_reviews', 'price', 'bathrooms', 'bedrooms', 'room_type']\nmissing_values = airbnb_data[relevant_columns].isnull().sum()\n\n# Display the missing values\nprint(\"Missing values in relevant columns:\\n\", missing_values)\n\n# Drop rows with missing values in relevant columns\nairbnb_data_clean = airbnb_data.dropna(subset=relevant_columns)\n\n# Check if any missing values remain\nmissing_values_after_drop = airbnb_data_clean[relevant_columns].isnull().sum()\nprint(\"\\nMissing values after dropping rows with missing values:\\n\", missing_values_after_drop)\n\n# Display the cleaned data (first few rows)\nairbnb_data_clean.head()\n\nMissing values in relevant columns:\n number_of_reviews      0\nprice                  0\nbathrooms            160\nbedrooms              76\nroom_type              0\ndtype: int64\n\nMissing values after dropping rows with missing values:\n number_of_reviews    0\nprice                0\nbathrooms            0\nbedrooms             0\nroom_type            0\ndtype: int64\n\n\n\n\n\n\n\n\n\nUnnamed: 0\nid\ndays\nlast_scraped\nhost_since\nroom_type\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\ninstant_bookable\n\n\n\n\n0\n1\n2515\n3130\n4/2/2017\n9/6/2008\nPrivate room\n1.0\n1.0\n59\n150\n9.0\n9.0\n9.0\nf\n\n\n1\n2\n2595\n3127\n4/2/2017\n9/9/2008\nEntire home/apt\n1.0\n0.0\n230\n20\n9.0\n10.0\n9.0\nf\n\n\n2\n3\n3647\n3050\n4/2/2017\n11/25/2008\nPrivate room\n1.0\n1.0\n150\n0\nNaN\nNaN\nNaN\nf\n\n\n3\n4\n3831\n3038\n4/2/2017\n12/7/2008\nEntire home/apt\n1.0\n1.0\n89\n116\n9.0\n9.0\n9.0\nf\n\n\n5\n6\n5099\n2981\n4/2/2017\n2/2/2009\nEntire home/apt\n1.0\n1.0\n212\n60\n9.0\n9.0\n9.0\nf\n\n\n\n\n\n\n\n\n\nPoisson Regression Model\n\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import poisson\n\n# Fit the Poisson regression model\nmodel = poisson('number_of_reviews ~ price + bathrooms + bedrooms + room_type', data=airbnb_data_clean).fit()\n\n# Display the model summary\nmodel_summary = model.summary()\nprint(model_summary)\n\nOptimization terminated successfully.\n         Current function value: 17.864838\n         Iterations 14\n                          Poisson Regression Results                          \n==============================================================================\nDep. Variable:      number_of_reviews   No. Observations:                40395\nModel:                        Poisson   Df Residuals:                    40389\nMethod:                           MLE   Df Model:                            5\nDate:                Wed, 07 May 2025   Pseudo R-squ.:                0.005345\nTime:                        20:04:09   Log-Likelihood:            -7.2165e+05\nconverged:                       True   LL-Null:                   -7.2553e+05\nCovariance Type:            nonrobust   LLR p-value:                     0.000\n=============================================================================================\n                                coef    std err          z      P&gt;|z|      [0.025      0.975]\n---------------------------------------------------------------------------------------------\nIntercept                     2.9065      0.004    661.204      0.000       2.898       2.915\nroom_type[T.Private room]    -0.1398      0.003    -49.040      0.000      -0.145      -0.134\nroom_type[T.Shared room]     -0.3895      0.009    -44.998      0.000      -0.406      -0.373\nprice                        -0.0005   1.24e-05    -40.928      0.000      -0.001      -0.000\nbathrooms                    -0.1052      0.004    -27.149      0.000      -0.113      -0.098\nbedrooms                      0.1042      0.002     51.830      0.000       0.100       0.108\n=============================================================================================\n\n\n\nInterpreting Coefficients\n\nIntercept: The intercept value of 2.9065 represents the log of the expected number of reviews for a listing with an average price, 0 bathrooms, 0 bedrooms, and the base room type (likely “Entire home/apt”). This acts as the baseline when all other variables are zero.\nPrivate Room: The coefficient for Private Room is -0.1398, indicating that, all else equal, listings with a private room tend to have 13.98% fewer reviews compared to the reference category, which is likely Entire home/apt. This suggests that private rooms attract fewer reviews.\nShared Room: The coefficient for Shared Room is -0.3895, meaning that shared room listings have 38.95% fewer reviews compared to entire homes/apartments. This suggests that shared rooms are generally less popular in terms of reviews, which might reflect lower occupancy rates or fewer bookings.\nPrice: The coefficient for price is -0.0005, meaning that for every additional dollar increase in price, the expected number of reviews decreases by approximately 0.05%. This suggests a slight negative relationship between price and the number of reviews, possibly indicating that higher-priced listings receive fewer bookings and reviews.\nBathrooms: The coefficient for bathrooms is -0.1052, indicating that each additional bathroom is associated with 10.52% fewer reviews. This negative relationship might reflect that larger listings (with more bathrooms) could be more expensive, leading to fewer bookings and reviews overall.\nBedrooms: The coefficient for bedrooms is 0.1042, meaning that each additional bedroom is associated with a 10.42% increase in the expected number of reviews. This positive relationship suggests that larger listings with more bedrooms tend to attract more reviews, likely due to higher occupancy rates.\n\n\n\n\nPredicting Reviews for New Data\n\n# Predict the number of reviews for all listings in the cleaned dataset\npredicted_reviews = model.predict(airbnb_data_clean)\n\n# Add predicted reviews to the dataset for further analysis\nairbnb_data_clean['predicted_reviews'] = predicted_reviews\n\n# Display the first few rows with predicted values\nairbnb_data_clean[['price', 'bathrooms', 'bedrooms', 'room_type', 'number_of_reviews', 'predicted_reviews']].head()\n\n/var/folders/6t/lkwvpnj13875sbb8yqc9c6pc0000gn/T/ipykernel_32241/1754208357.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  airbnb_data_clean['predicted_reviews'] = predicted_reviews\n\n\n\n\n\n\n\n\n\nprice\nbathrooms\nbedrooms\nroom_type\nnumber_of_reviews\npredicted_reviews\n\n\n\n\n0\n59\n1.0\n1.0\nPrivate room\n150\n15.421061\n\n\n1\n230\n1.0\n0.0\nEntire home/apt\n20\n14.648009\n\n\n2\n150\n1.0\n1.0\nPrivate room\n0\n14.723693\n\n\n3\n89\n1.0\n1.0\nEntire home/apt\n116\n17.465869\n\n\n5\n212\n1.0\n1.0\nEntire home/apt\n60\n16.406859\n\n\n\n\n\n\n\n\nConclusion:\nThe Poisson regression model provides insight into how different variables (such as price, bathrooms, bedrooms, and room_type) affect the expected number of reviews (a proxy for bookings).\nInterpreting the coefficients allows us to understand which factors have the most significant impact on review counts, which could help hosts optimize their listings for better visibility and more bookings."
  },
  {
    "objectID": "hw1/hw2_questions.html",
    "href": "hw1/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\ntodo: Read in data.\ntodo: Compare histograms and means of number of patents by customer status. What do you observe?\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\ntodo: Compare regions and ages by customer status. What do you observe?\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\ntodo: Write down mathematically the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\ntodo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:\npoisson_loglikelihood &lt;- function(lambda, Y){\n   ...\n}\ntodo: Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y).\ntodo: If you’re feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which “feels right” because the mean of a Poisson distribution is lambda.\ntodo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\ntodo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g_inv() to be exp() so that \\(\\lambda_i = e^{X_i'\\beta}\\). For example:\npoisson_regression_likelihood &lt;- function(beta, Y, X){\n   ...\n}\ntodo: Use your function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\ntodo: Check your results using R’s glm() function or Python sm.GLM() function.\ntodo: Interpret the results.\ntodo: What do you conclude about the effect of Blueprinty’s software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences."
  },
  {
    "objectID": "hw1/hw2_questions.html#blueprinty-case-study",
    "href": "hw1/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\ntodo: Read in data.\ntodo: Compare histograms and means of number of patents by customer status. What do you observe?\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\ntodo: Compare regions and ages by customer status. What do you observe?\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\ntodo: Write down mathematically the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\ntodo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:\npoisson_loglikelihood &lt;- function(lambda, Y){\n   ...\n}\ntodo: Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y).\ntodo: If you’re feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which “feels right” because the mean of a Poisson distribution is lambda.\ntodo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\ntodo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g_inv() to be exp() so that \\(\\lambda_i = e^{X_i'\\beta}\\). For example:\npoisson_regression_likelihood &lt;- function(beta, Y, X){\n   ...\n}\ntodo: Use your function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\ntodo: Check your results using R’s glm() function or Python sm.GLM() function.\ntodo: Interpret the results.\ntodo: What do you conclude about the effect of Blueprinty’s software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences."
  },
  {
    "objectID": "hw1/hw2_questions.html#airbnb-case-study",
    "href": "hw1/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\ntodo: Assume the number of reviews is a good proxy for the number of bookings. Perform some exploratory data analysis to get a feel for the data, handle or drop observations with missing values on relevant variables, build one or more models (e.g., a poisson regression model for the number of bookings as proxied by the number of reviews), and interpret model coefficients to describe variation in the number of reviews as a function of the variables provided."
  },
  {
    "objectID": "blog/Project 5/hw3_questions.html",
    "href": "blog/Project 5/hw3_questions.html",
    "title": "Multinomial Logit Model",
    "section": "",
    "text": "This assignment expores two methods for estimating the MNL model: (1) via Maximum Likelihood, and (2) via a Bayesian approach using a Metropolis-Hastings MCMC algorithm."
  },
  {
    "objectID": "blog/Project 5/hw3_questions.html#likelihood-for-the-multi-nomial-logit-mnl-model",
    "href": "blog/Project 5/hw3_questions.html#likelihood-for-the-multi-nomial-logit-mnl-model",
    "title": "Multinomial Logit Model",
    "section": "1. Likelihood for the Multi-nomial Logit (MNL) Model",
    "text": "1. Likelihood for the Multi-nomial Logit (MNL) Model\nSuppose we have \\(i=1,\\ldots,n\\) consumers who each select exactly one product \\(j\\) from a set of \\(J\\) products. The outcome variable is the identity of the product chosen \\(y_i \\in \\{1, \\ldots, J\\}\\) or equivalently a vector of \\(J-1\\) zeros and \\(1\\) one, where the \\(1\\) indicates the selected product. For example, if the third product was chosen out of 3 products, then either \\(y=3\\) or \\(y=(0,0,1)\\) depending on how we want to represent it. Suppose also that we have a vector of data on each product \\(x_j\\) (eg, brand, price, etc.).\nWe model the consumer’s decision as the selection of the product that provides the most utility, and we’ll specify the utility function as a linear function of the product characteristics:\n\\[ U_{ij} = x_j'\\beta + \\epsilon_{ij} \\]\nwhere \\(\\epsilon_{ij}\\) is an i.i.d. extreme value error term.\nThe choice of the i.i.d. extreme value error term leads to a closed-form expression for the probability that consumer \\(i\\) chooses product \\(j\\):\n\\[ \\mathbb{P}_i(j) = \\frac{e^{x_j'\\beta}}{\\sum_{k=1}^Je^{x_k'\\beta}} \\]\nFor example, if there are 3 products, the probability that consumer \\(i\\) chooses product 3 is:\n\\[ \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{e^{x_1'\\beta} + e^{x_2'\\beta} + e^{x_3'\\beta}} \\]\nA clever way to write the individual likelihood function for consumer \\(i\\) is the product of the \\(J\\) probabilities, each raised to the power of an indicator variable (\\(\\delta_{ij}\\)) that indicates the chosen product:\n\\[ L_i(\\beta) = \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} = \\mathbb{P}_i(1)^{\\delta_{i1}} \\times \\ldots \\times \\mathbb{P}_i(J)^{\\delta_{iJ}}\\]\nNotice that if the consumer selected product \\(j=3\\), then \\(\\delta_{i3}=1\\) while \\(\\delta_{i1}=\\delta_{i2}=0\\) and the likelihood is:\n\\[ L_i(\\beta) = \\mathbb{P}_i(1)^0 \\times \\mathbb{P}_i(2)^0 \\times \\mathbb{P}_i(3)^1 = \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{\\sum_{k=1}^3e^{x_k'\\beta}} \\]\nThe joint likelihood (across all consumers) is the product of the \\(n\\) individual likelihoods:\n\\[ L_n(\\beta) = \\prod_{i=1}^n L_i(\\beta) = \\prod_{i=1}^n \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} \\]\nAnd the joint log-likelihood function is:\n\\[ \\ell_n(\\beta) = \\sum_{i=1}^n \\sum_{j=1}^J \\delta_{ij} \\log(\\mathbb{P}_i(j)) \\]"
  },
  {
    "objectID": "blog/Project 5/hw3_questions.html#simulate-conjoint-data",
    "href": "blog/Project 5/hw3_questions.html#simulate-conjoint-data",
    "title": "Multinomial Logit Model",
    "section": "2. Simulate Conjoint Data",
    "text": "2. Simulate Conjoint Data\nWe will simulate data from a conjoint experiment about video content streaming services. We elect to simulate 100 respondents, each completing 10 choice tasks, where they choose from three alternatives per task. For simplicity, there is not a “no choice” option; each simulated respondent must select one of the 3 alternatives.\nEach alternative is a hypothetical streaming offer consistent of three attributes: (1) brand is either Netflix, Amazon Prime, or Hulu; (2) ads can either be part of the experience, or it can be ad-free, and (3) price per month ranges from $4 to $32 in increments of $4.\nThe part-worths (ie, preference weights or beta parameters) for the attribute levels will be 1.0 for Netflix, 0.5 for Amazon Prime (with 0 for Hulu as the reference brand); -0.8 for included adverstisements (0 for ad-free); and -0.1*price so that utility to consumer \\(i\\) for hypothethical streaming service \\(j\\) is\n\\[\nu_{ij} = (1 \\times Netflix_j) + (0.5 \\times Prime_j) + (-0.8*Ads_j) - 0.1\\times Price_j + \\varepsilon_{ij}\n\\]\nwhere the variables are binary indicators and \\(\\varepsilon\\) is Type 1 Extreme Value (ie, Gumble) distributed.\nThe following code provides the simulation of the conjoint data.\n\n\n\n\n\n\nNote"
  },
  {
    "objectID": "blog/Project 5/hw3_questions.html#preparing-the-data-for-estimation",
    "href": "blog/Project 5/hw3_questions.html#preparing-the-data-for-estimation",
    "title": "Multinomial Logit Model",
    "section": "3. Preparing the Data for Estimation",
    "text": "3. Preparing the Data for Estimation\nThe “hard part” of the MNL likelihood function is organizing the data, as we need to keep track of 3 dimensions (consumer \\(i\\), covariate \\(k\\), and product \\(j\\)) instead of the typical 2 dimensions for cross-sectional regression models (consumer \\(i\\) and covariate \\(k\\)). The fact that each task for each respondent has the same number of alternatives (3) helps. In addition, we need to convert the categorical variables for brand and ads into binary variables.\n\nimport pandas as pd\nimport numpy as np\n\n# Load data\nconjoint_data = pd.read_csv(\"conjoint_data.csv\")\n\n# One-hot encode brand and ad with reference levels: brand=H, ad=No\nX = pd.get_dummies(conjoint_data, columns=[\"brand\", \"ad\"], drop_first=True)\n\n# Define feature and metadata columns\nfeature_cols = [\"brand_N\", \"brand_P\", \"ad_Yes\", \"price\"]\nmeta_cols = [\"resp\", \"task\", \"choice\"]\n\n# Prepare final DataFrame\nX_features = X[feature_cols]\nmeta = conjoint_data[meta_cols].reset_index(drop=True)\nX_full = pd.concat([meta, X_features], axis=1)\n\n# Reshape into 3D array (n_obs, n_alts, n_features) and choice vector\nn_alts = 3\nn_obs = X_full.shape[0] // n_alts\nn_features = len(feature_cols)\n\nX_arr = np.zeros((n_obs, n_alts, n_features))\ny = np.zeros(n_obs, dtype=int)\n\nfor i in range(n_obs):\n    start = i * n_alts\n    end = start + n_alts\n    X_arr[i, :, :] = X_full.iloc[start:end][feature_cols].values\n    y[i] = np.argmax(X_full.iloc[start:end]['choice'].values)\n\n# Output dimensions\nprint(\"X_arr shape:\", X_arr.shape)  # (1000, 3, 4)\nprint(\"y shape:\", y.shape)          # (1000,)\n\nX_arr shape: (1000, 3, 4)\ny shape: (1000,)"
  },
  {
    "objectID": "blog/Project 5/hw3_questions.html#estimation-via-maximum-likelihood",
    "href": "blog/Project 5/hw3_questions.html#estimation-via-maximum-likelihood",
    "title": "Multinomial Logit Model",
    "section": "4. Estimation via Maximum Likelihood",
    "text": "4. Estimation via Maximum Likelihood\n\nfrom scipy.optimize import minimize\nfrom scipy.special import logsumexp\nimport numpy as np\n\n# Define the log-likelihood function for the MNL model\ndef mnl_log_likelihood(beta, X_arr, y):\n    \"\"\"\n    Compute negative log-likelihood for the MNL model.\n\n    Parameters:\n    - beta: parameter vector of shape (n_features,)\n    - X_arr: array of shape (n_obs, n_alts, n_features)\n    - y: vector of shape (n_obs,) indicating chosen alternative\n\n    Returns:\n    - negative log-likelihood (to minimize)\n    \"\"\"\n    n_obs, n_alts, n_features = X_arr.shape\n    utilities = np.dot(X_arr, beta)  # shape: (n_obs, n_alts)\n    log_prob = utilities - logsumexp(utilities, axis=1, keepdims=True)\n    chosen_log_prob = log_prob[np.arange(n_obs), y]\n    return -np.sum(chosen_log_prob)\n\nUsing optim() in R or scipy.optimize() in Python to find the MLEs for the 4 parameters (\\(\\beta_\\text{netflix}\\), \\(\\beta_\\text{prime}\\), \\(\\beta_\\text{ads}\\), \\(\\beta_\\text{price}\\)), as well as their standard errors (from the Hessian). For each parameter constructed a 95% confidence interval.\n\n# Initial guess\nbeta_init = np.zeros(X_arr.shape[2])\n\n# Optimize using BFGS\nresult = minimize(\n    mnl_log_likelihood,\n    beta_init,\n    args=(X_arr, y),\n    method='BFGS',\n    options={'disp': True}\n)\n\n# Extract results\nbeta_hat = result.x\nhessian_inv = result.hess_inv  # inverse Hessian from BFGS\n\n# Standard errors and 95% confidence intervals\nse = np.sqrt(np.diag(hessian_inv))\nconf_int = np.vstack([beta_hat - 1.96 * se, beta_hat + 1.96 * se]).T\n\n# Display results\nfor name, est, std, ci in zip([\"Netflix\", \"Prime\", \"Ads\", \"Price\"], beta_hat, se, conf_int):\n    print(f\"{name:&gt;8}: {est:.3f} ± {1.96*std:.3f}  (95% CI: {ci[0]:.3f}, {ci[1]:.3f})\")\n\nOptimization terminated successfully.\n         Current function value: 879.855368\n         Iterations: 12\n         Function evaluations: 85\n         Gradient evaluations: 17\n Netflix: 0.941 ± 0.223  (95% CI: 0.718, 1.165)\n   Prime: 0.502 ± 0.237  (95% CI: 0.265, 0.738)\n     Ads: -0.732 ± 0.174  (95% CI: -0.906, -0.558)\n   Price: -0.099 ± 0.012  (95% CI: -0.112, -0.087)"
  },
  {
    "objectID": "blog/Project 5/hw3_questions.html#estimation-via-bayesian-methods",
    "href": "blog/Project 5/hw3_questions.html#estimation-via-bayesian-methods",
    "title": "Multinomial Logit Model",
    "section": "5. Estimation via Bayesian Methods",
    "text": "5. Estimation via Bayesian Methods\n\nMetropolis-hasting MCMC sampler of the posterior distribution\n\n# Define log prior: N(0,5) for first 3, N(0,1) for price\ndef log_prior(beta):\n    logp = 0\n    logp += -0.5 * np.sum((beta[:3] / 5) ** 2) - 3 * np.log(np.sqrt(2 * np.pi * 25))\n    logp += -0.5 * (beta[3] ** 2) - np.log(np.sqrt(2 * np.pi))\n    return logp\n\n# Define log posterior: log-likelihood + log-prior\ndef log_posterior(beta, X_arr, y):\n    return -mnl_log_likelihood(beta, X_arr, y) + log_prior(beta)\n\n# Metropolis-Hastings algorithm\nn_iter = 11000\nburn_in = 1000\nbeta_dim = 4\nsamples = np.zeros((n_iter, beta_dim))\naccepts = 0\n\n# Initialize at zeros\ncurrent_beta = np.zeros(beta_dim)\ncurrent_log_post = log_posterior(current_beta, X_arr, y)\n\n# Proposal standard deviations\nproposal_sd = np.array([0.05, 0.05, 0.05, 0.005])\n\nfor i in range(n_iter):\n    # Propose new beta\n    proposal = current_beta + np.random.normal(0, proposal_sd)\n    proposal_log_post = log_posterior(proposal, X_arr, y)\n\n    # Acceptance probability\n    log_accept_ratio = proposal_log_post - current_log_post\n    if np.log(np.random.rand()) &lt; log_accept_ratio:\n        current_beta = proposal\n        current_log_post = proposal_log_post\n        accepts += 1\n\n    samples[i] = current_beta\n\n# Discard burn-in\nposterior_samples = samples[burn_in:]\n\n# Calculate posterior means and 95% credible intervals\nposterior_mean = posterior_samples.mean(axis=0)\nposterior_ci = np.percentile(posterior_samples, [2.5, 97.5], axis=0).T\n\nposterior_mean, posterior_ci, accepts / n_iter\n\n(array([ 0.94513475,  0.49698603, -0.73186795, -0.09985149]),\n array([[ 0.73501008,  1.16658556],\n        [ 0.28371069,  0.70596791],\n        [-0.90609619, -0.55379772],\n        [-0.11153944, -0.0879256 ]]),\n 0.5677272727272727)\n\n\n\n\nTrace plot of the algorithm, and the histogram of the posterior distribution.\n\nimport matplotlib.pyplot as plt\n\n# Choose one parameter to visualize, e.g., Netflix coefficient (index 0)\nparam_idx = 0\nparam_name = \"β_Netflix\"\ntrace = posterior_samples[:, param_idx]\n\n# Plot trace and histogram\nfig, axs = plt.subplots(2, 1, figsize=(10, 6), sharex=False)\n\n# Trace plot\naxs[0].plot(trace, color='blue')\naxs[0].set_title(f\"Trace Plot of {param_name}\")\naxs[0].set_ylabel(\"Parameter Value\")\n\n# Histogram\naxs[1].hist(trace, bins=40, density=True, color='skyblue', edgecolor='black')\naxs[1].set_title(f\"Posterior Distribution of {param_name}\")\naxs[1].set_xlabel(\"Parameter Value\")\naxs[1].set_ylabel(\"Density\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nThe 4 posterior means, standard deviations, and 95% credible intervals and comparison of the results from the Maximum Likelihood approach.\n\n# Calculate posterior standard deviations\nposterior_std = posterior_samples.std(axis=0)\n\n# Prepare a summary table\nparam_names = [\"β_Netflix\", \"β_Prime\", \"β_Ads\", \"β_Price\"]\nmle_estimates = beta_hat\nmle_se = se\nmle_ci = conf_int\n\nimport pandas as pd\n\nsummary_df = pd.DataFrame({\n    \"Parameter\": param_names,\n    \"Posterior Mean\": posterior_mean,\n    \"Posterior Std. Dev.\": posterior_std,\n    \"Bayesian 95% CI Lower\": posterior_ci[:, 0],\n    \"Bayesian 95% CI Upper\": posterior_ci[:, 1],\n    \"MLE Estimate\": mle_estimates,\n    \"MLE Std. Error\": mle_se,\n    \"MLE 95% CI Lower\": mle_ci[:, 0],\n    \"MLE 95% CI Upper\": mle_ci[:, 1]\n})\nprint(summary_df)\n\n   Parameter  Posterior Mean  Posterior Std. Dev.  Bayesian 95% CI Lower  \\\n0  β_Netflix        0.945135             0.107195               0.735010   \n1    β_Prime        0.496986             0.109676               0.283711   \n2      β_Ads       -0.731868             0.090620              -0.906096   \n3    β_Price       -0.099851             0.006070              -0.111539   \n\n   Bayesian 95% CI Upper  MLE Estimate  MLE Std. Error  MLE 95% CI Lower  \\\n0               1.166586      0.941195        0.113988          0.717780   \n1               0.705968      0.501616        0.120859          0.264732   \n2              -0.553798     -0.731994        0.088580         -0.905611   \n3              -0.087926     -0.099480        0.006358         -0.111942   \n\n   MLE 95% CI Upper  \n0          1.164611  \n1          0.738499  \n2         -0.558377  \n3         -0.087019"
  },
  {
    "objectID": "blog/Project 5/hw3_questions.html#discussion",
    "href": "blog/Project 5/hw3_questions.html#discussion",
    "title": "Multinomial Logit Model",
    "section": "6. Discussion",
    "text": "6. Discussion\n\nInterpreting the Parameter Estimates\nEven without knowing the true part-worths, the estimated values give clear insight into consumer preferences based on revealed choices in the conjoint tasks.\nβNetflix &gt; βPrime &gt; 0 This implies that, all else equal, consumers prefer Netflix over Prime, and Prime over Hulu (since Hulu is the reference category). The magnitudes suggest stronger preference for Netflix.\nβAds &lt; 0 The negative sign indicates that including advertisements makes a product less attractive to consumers. This aligns with what you’d expect in practice: ad-free experiences are preferred.\nβPrice &lt; 0 A negative price coefficient is economically intuitive — it means that as price increases, the utility of a product decreases, making it less likely to be chosen. This validates the logic of price sensitivity in consumer decision-making.\nWhat Does βNetflix &gt; βPrime Mean?\nIt means that consumers derive higher utility from Netflix than from Amazon Prime, holding ad presence and price constant. So, for two identical products (same price and ad policy), one labeled “Netflix” and the other “Prime”, consumers are more likely to choose Netflix."
  },
  {
    "objectID": "blog/Project 5/hw3_questions.html#extending-to-a-multi-level-hierarchical-mnl-model",
    "href": "blog/Project 5/hw3_questions.html#extending-to-a-multi-level-hierarchical-mnl-model",
    "title": "Multinomial Logit Model",
    "section": "Extending to a Multi-Level (Hierarchical) MNL Model",
    "text": "Extending to a Multi-Level (Hierarchical) MNL Model\nIn the standard Multinomial Logit (MNL) model, we assume that all respondents share the same set of preference parameters. This is known as a fixed-effects model and implies a homogeneous population — that every consumer values product attributes in exactly the same way. While this simplification makes the model easier to estimate, it is often unrealistic in real-world settings where individuals exhibit different tastes, priorities, and sensitivities.\nTo address this limitation, we can adopt a multi-level (also known as hierarchical or random-parameter) MNL model. In this framework, each individual is allowed to have their own set of preference parameters. Specifically, each person’s vector of utility weights, 𝛽𝑖 , is assumed to be drawn from a population-level distribution, typically a multivariate normal distribution with mean 𝜇 and covariance matrix Σ. This allows us to model both the average preferences across the population and the individual-level deviations from that average.\nSimulating data under this model involves generating a unique 𝛽𝑖 for each respondent from the population distribution and then using that respondent-specific vector to simulate choices. Estimating the model, in turn, requires recovering both the distributional parameters ( 𝜇 and Σ) and, optionally, the individual-level parameters (𝛽𝑖). This is more computationally intensive and typically requires Bayesian methods, such as Markov Chain Monte Carlo (MCMC), or advanced frequentist approaches like simulated maximum likelihood.\nThe hierarchical MNL model is especially useful in analyzing real-world conjoint data because it captures heterogeneity in preferences — a critical feature when designing products, segmenting markets, or setting personalized pricing strategies. By allowing for individual-level variation, the model provides deeper and more realistic insights into consumer decision-making."
  }
]